\chapter{Preliminares}\label{chapter:state-of-the-art}

La optimización binivel es un problema de optimización donde un subconjunto de variables debe ser la solución óptima de otro problema de optimización, parametrizado por las variables restantes. Este problema tiene dos niveles jerárquicos de decisión: el nivel superior (líder) y el nivel inferior (seguidor).
Este tiene dos características principales: primero, el problema del nivel inferior actúa como una restricción para el nivel superior; segundo, la solución del nivel inferior depende de las variables del nivel superior, creando una interdependencia entre ambos niveles. Por ello, el líder debe anticipar la respuesta óptima del seguidor al tomar decisiones.
%Explicación breve de binivel
En términos abstractos, la optimización binivel busca minimizar una función objetivo de nivel superior, $F(x, y)$, donde $x$ son las variables de decisión del líder y $y$ son las variables del seguidor. 

% Explicación del capitulo
En este capítulo se abordará los conocimientos necesarios para el desarrollo de esta tesis. La primera sección trata  sobre Optimización Binivel: la definición de solución basada en la existencia de una cierta cooperación entre lideres y seguidores (caso  optimista) y la reformulación KKT. Luego se presentan los conceptos fundamentales  de solución, regularidad y estacionariedad para Problemas Matemáticos con Restricciones de Equilibrio (MPEC). La tercera sección contiene las principales transformaciones que se aplican a las restricciones de complementariedad para la solución numérica del modelo. Por último, se presenta la modelación de los problemas binivel en el lenguaje de programación Julia y los métodos seleccionados implementados en este lenguaje para su resolución. 

\section{Optimización Binivel }
%Intro de la sección
El problema de optimización binivel en general se define de la siguiente manera \begin{equation} \label{eq:Def1Binivel}
    \begin{array}{l}
      \displaystyle \min_{x} \quad F(x, y)\\
        s.a \left\{ \begin{array}{l}
            x \in \cal{T} \\
             y \in S(x) = \arg \displaystyle  \min_{y} \{ f(x, y) \quad s.a \quad y \in  \cal{H}\}\\
            (x,y) \in {\cal{M}}^0 
        \end{array}\right.
        \end{array} \end{equation}
En la mayoría de las aplicaciones, los problemas de optimización del nivel inferior y superior son modelos de programación matemática, por lo  que, sin pérdida de generalidad, se asume que  ${\cal{T}}=\mathbb{R}^n$,  $\cal{H}$ es  $\{y\in \mathbb{R}^m\in v_j(x, y)\leq 0,\;j=1,\ldots,q\}$  y
  ${\cal{M}}^0=\{(x,y)\in\mathbb{R}^{n+m},\;g_i(x, y)\leq 0,\;i=1,\ldots,q\}$. El problema es  
\begin{equation}
\begin{aligned}
& \min_{x} \; F(x, y) \\
& \text{sujeto a } \\
& g_i(x, y)\leq 0,\;i=1,\ldots,q, \\
& y \in \argmin_{y} \left\{ f(x, y) \mid v_j(x, y)\leq 0,\;j=1,\ldots,q \right\}
\end{aligned}
\label{eq:ProblemaGeneral}
\end{equation}
donde 
$    x \in R^{n},\; y \in R^{m}$, $ F(x,y) : \mathbb{R}^{n} \times \mathbb{R}^{m} \to \mathbb{R},$ $ g_i(x,y)  : \mathbb{R}^{n} \times \mathbb{R}^{m} \to \mathbb{R} ,$, $i=1,\ldots, q$,  $f(x,y) : \mathbb{R}^{n} \times \mathbb{R}^{m} \to \mathbb{R},$  $v_j(x,y)  : \mathbb{R}^{n} \times \mathbb{R}^{m} \to \mathbb{R} ,$ $j=1,\ldots, s$.
En el enfoque optimista, se asume que el seguidor, que actúa en el nivel inferior, elegirá la solución más favorable para el líder, quien toma decisiones en el nivel superior. Este es considerado más tratable y, en ciertas situaciones favorables, puede simplificarse a un problema convexo. Además, en el contexto de múltiples objetivos, el enfoque optimista permite alcanzar el mejor frente de Pareto posible, ver \cite{DempeyZemkoho2020}.

%\begin{center}   
%    Bajo el enfoque optimista :
%    \end{center}
    % Enfoque optimista (selección favorable)
    \begin{equation}  \label{eq:EnfoqueOptimistaGeneral}
    \begin{matrix}
    & \displaystyle \min_{x} \; \inf_{y \in S(x)} F(x, y) \\& g_i(x, y)\leq 0,\;i=1,\ldots,q, \\
    & \text{con } S(x) = \displaystyle \argmin_{y} \left\{ f(x, y) \mid v(x, y) \leq 0 \right\}
    \end{matrix}
    \end{equation}
    \captionof{figure}{Problema de optimización bajo el enfoque optimista.}

% Enfoque pesimista
Por otro lado, el enfoque pesimista asume que el seguidor seleccionará la opción menos favorable para el líder entre las soluciones óptimas disponibles, el cual es más complejo de resolver y puede incluso no tener solución. A menudo, se requieren reformulaciones para abordar estos problemas, lo que lo convierte en un reto teórico y computacional significativo en situaciones de múltiples objetivos, conduce al peor frente de Pareto posible, ver \cite{Sinha2017ARO}.
%\begin{center}
%    Bajo el enfoque pesimista:
%\end{center}
% Enfoque pesimista (peor caso)
\begin{equation}
\begin{aligned}
    & \min_{x} \; \sup_{y \in S(x)} F(x, y) \\& g_i(x, y)\leq 0,\;i=1,\ldots,q, \\
& \text{con } S(x) = \argmin_{y} \left\{ f(x, y) \mid v(x, y) \leq 0 \right\}
\end{aligned}
\label{eq:EnfoquePesimistaGeneral}
\end{equation}
\captionof{figure}{Problema de optimización bajo el enfoque pesimista.}
%Decir que el optimista es mejor
Es relevante destacar que la mayoría de la literatura se centra en el enfoque optimista debido a su mayor facilidad de tratamiento. Sin embargo, el otro también tiene su utilidad, especialmente en la modelación de situaciones donde se considera la aversión al riesgo, ver \cite{DempeyZemkoho2020}. En este contexto, los términos ''líder'' y ''seguidor'' se utilizan para describir los roles en el modelo a optimizar; el líder toma decisiones considerando las posibles reacciones del seguidor, quien a su vez reacciona seleccionando su mejor opción, ver \cite{Sinha2017ARO}.

% Decir que se va ha hablar del enfoque optimista
Dado que en la tesis trataremos sobre problemas binivel de enfoque optimista mostraremos algunos resultados referidos al modelo resultante.

Primeramente es importante notar el siguiente resultado, ver \cite{Scmidtbiblio}.

\begin{proposition} El problema de optimización binivel optimista \eqref{eq:EnfoqueOptimistaGeneral} se formula equivalentemente como:
\begin{equation}\label{eq:DefBinivelOptimista} 
\begin{matrix}
  \displaystyle  \min_{x , y} & \quad F(x, y) \notag \\
    \text{s.t.} & \quad g_i(x, y) \leq 0, i=1\ldots q,  \notag \\
    & \quad y \in S(x), \end{matrix}\end{equation}
  
donde $S(x)$ es el conjunto de soluciones óptimas del problema parametrizado por $x$ 
 \begin{equation}
\begin{matrix} \displaystyle  \min_{y \in Y(x)} & \quad f(x, y)  
    \text{s.t.} & \quad v_j(x, y) \leq 0, j=1\ldots s, \notag \end{matrix}\end{equation}


\end{proposition}
De ahí  que a partir de ahora se considerará el problema \eqref{eq:DefBinivelOptimista} y se le llamará indistintamente problema de dos niveles. 
 % Hablar sobre el enfoque optimista
%En el caso del enfoque optimista si para el nivel inferior existen más de un punto que resuelve el problema del nivel inferior y tomará la que más beneficie al nivel superior. 
 % Decir que solo restricciones desigualdad
Los  problemas de dos niveles pueden ser reformulados en un problema de un solo nivel al reemplazar el problema del nivel inferior por las condiciones KKT de este en las restricciones del primer nivel. 
		
		%Para el caso de los SLSMG donde se tiene un problema de optimización en el nivel inferior este sustituye por de las condiciones KKT de este, obteniendo un MPEC \autocite{aussel2020}.
        
% 
        \begin{equation}   
            \begin{array}{l}
                \underset{\substack{x, y, \lambda_j}}{\min} \quad F(x, y)\\
                s.a \left\{ 
                \begin{array}{l}
                    g_i(x, y) \leq 0, i=1\ldots q,\\
                    \nabla_{y} f(x, y) + \sum_{j=1}^{s} \nabla_{y} v_j(x, y) \lambda_j = 0, \\
                    v_j(x, y) \leq 0, j=1\ldots s,\\
                    v_j(x, y)\lambda_j = 0, j=1\ldots s, \\
                    \lambda_j \geq 0, j=1\ldots s.\\
                \end{array}\right.
            \end{array}
            \label{eq:KKT_Optimista}
        \end{equation}
     

% Añadir aclaratoria
Los tres últimos grupos de restricciones expresan que $v$ y $\lambda$ están restringidas en signo y que al menos una es 0. Estas condiciones son conocidas como \textbf{restricciones de complementariedad}. Estos modelos corresponden a la clase de problemas de programación matemática con restricciones de complementariedad (MPEC). 
Como se mencionó en la introducción, existe un enfoque alternativo mediante un problema de programación matemática utilizando la función del valor extremal. Sin embargo, esta función carece de una expresión explícita, exceptuando casos muy específicos. La ventaja del método KKT para MPEC radica en que proporciona una forma explícita, aunque requiere ciertas condiciones de regularidad del conjunto, como la Condición de Calificación de Restricciones de Independencia Lineal (LICQ), por sus siglas en ingles, de las restricciones activas. En caso de no cumplirse estas condiciones, podrían existir puntos óptimos que no satisfagan las condiciones KKT.
A continuación, presentamos los resultados de esta área necesarios para el desarrollo de esta tesis.

\section{Programación Matemática con Restricciones de Equilibrio (MPEC)}
%Aca va la sección que explica los MPEC
% Que es un MPEC
Un \textbf{problema de Programación Matemático con Restricciones de Equilibrio (MPEC)} es un tipo de  problema de optimización no lineal que incluye restricciones de equilibrio, específicamente, restricciones de complementariedad.

%Formula MPEC Genérico
\begin{equation}
\begin{aligned}
\min  &\quad  f(z)  \\
\text{s.t.} &\quad \begin{matrix} g_i(z)& \leq& 0, &i=1,\ldots,q, \\ h_k(z) &=& 0,&k=1\ldots,m, \\
 G_j(z) &\geq& 0, & j=1,\ldots,s,& H_j(z) &\geq& 0, & j=1,\ldots,s, \end{matrix}
\\&G_j(z)^T H_j(z) = 0,\; j=1,\ldots,s. \\
&\text{Definición de MPEC} \\
\end{aligned}  
%\tag{\theequation} 
\label{eq:DefMpec}
\end{equation}

%Dimensiones MPEC Genérico
donde $f: \mathbb{R}^{\hat{n}} \to \mathbb{R}$, $g: \mathbb{R}^{\hat{n}} \to \mathbb{R}$, $h: \mathbb{R}^{\hat{n}} \to \mathbb{R}$, $G: \mathbb{R}^{\hat{n}} \to \mathbb{R}$, y $H: \mathbb{R}^{\hat{n}} \to \mathbb{R}$ son funciones continuamente diferenciables. 
El término de complementariedad se debe a la existencia de las restricciones homónimas 
%Ecuación para poner que son las restricciones de complementariedad
\begin{equation}
    G_j(z) \geq 0, \; H_j(z) \geq 0, \quad G_j(z)^T H_j(z) = 0,\quad  j=1,\ldots,s. \\ \label{eq:RestriccionesComplementariedadAbstracto}
\end{equation}

Debido a las restricciones de complementariedad, los MPEC no cumplen con las condiciones de regularidad estándar, lo que hace que las condiciones de KKT no sean directamente aplicables como condiciones de optimalidad de primer orden. Los MPEC son utilizados para modelar problemas donde existen restricciones de equilibrio, como problemas de ingeniería y economía, ver \cite{Flegel2003AFJ,DempeyZemkoho2020}.


%\subsection{Resultados sobre MPECs}

%Notación de los indices activos del documento
A continuación como en \cite{Flegel2003AFJ}, se introduce las siguientes definiciones, útiles para la obtención de condiciones necesarias de optimalidad.
\begin{definition}[Conjunto de Índices]
Dado un vector factible $z^*$ del MPEC \eqref{eq:DefMpec}, definimos los siguientes \textit{conjuntos de índices}:
\begin{equation}
\begin{aligned}
J_G&:=& J_G(z^*) := \{i|G_i(z^*) = 0, H_i(z^*) > 0\} \\
J_{GH}&:=& J_{GH}(z^*) := \{i|G_i(z^*) = 0, H_i(z^*) = 0\}  \\
J_H &:= &J_H(z^*) := \{i|G_i(z^*) > 0, H_i(z^*) = 0\}  \\
\end{aligned}
\label{eq:ConjuntoDeIndices} 
\end{equation}
\end{definition}

% Definición de TNLP Problema No Lineal Ajustado
Para definir condiciones de regularidad para MPEC, introducimos el siguiente problema, dependiente de $z^*$:

\begin{definition}[Programa No Lineal Relacionado (RNLP)]

Un \textit{Programa No Lineal Relacionado $RNLP_{a,b} := RNLP_{a,b}(z^*)$} es:
\begin{equation}
\begin{aligned}
\min  &\quad  f(z)  \\
\text{s.t.} &\quad \begin{matrix} g_i(z)& \leq& 0, &i=1,\ldots,q, \\ h_k(z) &=& 0,&k=1\ldots,m, \\
 G_j(z) &=& 0, & j\in J_G\cup J_{a},& G_j(z) &\geq& 0, & j\in J_H,\\ 
H_j(z) &=& 0, & j\in J_H\cup J_{b},& H_j(z) &\geq& 0, & j\in J_G,\end{matrix}\\
& \text{Problema No Lineal Relacionado (RNLP)}  
\end{aligned}
\label{eq:ProblemaAbstractoTNLP}
\end{equation}
    donde $a\cup b=J_{GH}$.
\end{definition}

El RLNP \eqref{eq:ProblemaAbstractoTNLP} puede  usarse para definir variantes de regularidad y condiciones necesarias de optimalidad  adecuadas para MPEC como son la  restricción estándar de independencia lineal (LICQ en su forma abreviada) y la de punto de KKT .

\begin{definition}[MPEC-LICQ]
El MPEC \eqref{eq:DefMpec} se dice que satisface la \textit{MPEC-LICQ}  en un vector factible $z^*$ si los correspondientes $RNLP_{a,b}(z^*)$ satisfacen la LICQ  en ese vector $z^*$.
\end{definition}
    Cabe destacar que si la LICQ se cumple en  $RNLP_{a,b}(z^*)$ para una partición $(a,b)$ se cumple para todas. 
%TODO: Hacer notar que un mínimo de z^* implica la existencia de \lambda^* ....
%En este punto, es importante notar que bajo MPEC-MFCQ, un mínimo local $z^*$ del MPEC \eqref{eq:DefMpec} implica la existencia de un multiplicador de Lagrange $\lambda^*$ tal que $(z^*, \lambda^*)$ satisface las condiciones KKT para el programa \eqref{eq:ProblemaAbstractoTNLP}. Por lo tanto, si asumimos que MPEC-MFCQ se cumple para un mínimo local $z^*$ del MPEC \eqref{eq:DefMpec}, podemos usar cualquier multiplicador de Lagrange $\lambda^*$ (que ahora se sabe que existe) para definir el MPEC-SMFCQ, es decir, tomando $(z^*, \lambda^*)$.

%Definición de los puntos estacionarios del MPEC
% Flegel and Kanzow 2003
En el contexto de los MPEC en \cite{Flegel2003AFJ} se exponen varios tipos de puntos estacionarios que son cruciales para analizar la optimalidad, los cuales son los siguientes:
\begin{definition}[Punto Factible]
    Un \textit{punto factible} $z^*$ del MPEC se llama débilmente estacionario si existe un multiplicador de Lagrange $ (\mu, \alpha, \beta, \gamma)$ tal que se cumplen las siguientes condiciones:
    
% USar multiplicadores análogos a como esta en el binivel de miu lambda beta 
% EN este orden  mui-g, alpha-h beta-G gamma-H
\begin{align}
& \nabla f(z^*) + \sum_{i=1}^q \mu_i\nabla g_i(z^*) + \sum_{k=1}^{q_0} \alpha_k\nabla h_k(z^*) - \sum_{j=1}^{s} [\beta_j\nabla G_j(z^*) + \gamma_j\nabla H_j(z^*)] = \vec{0} \notag\\
    & \quad \begin{aligned}
        & \beta_j,\; j\in {J_G} \text{ libre}, \quad  \beta_j,\; j\in _{J_G\cup J_{GH}} \text{ libre}, \quad \beta_j,\; j\in _{J_H}= 0, \\
        &  \gamma_j,\; j\in _{J_H} \text{ libre}, \quad  \gamma_j,\; j\in _{J_G\cup J_{GH}} \text{ libre}, \quad \gamma_j,\; j\in _{J_G}= 0,  \\
        & g_i(z^*) \leq 0, \quad \mu_i \geq 0, \quad \mu_i g_i(z^*) = 0, i=1,\ldots, q.
    \end{aligned} \\
& \label{eq:Definición_punto_debilemente_estacionario} \notag
\end{align}
\end{definition}

% Definición de puntos estacionarios
Este concepto de estacionariedad es equivalente al cumplimiento de la estacionariedad clásica en el problema $RNLP_{J_{GH},J_{GH}}$. De ahí que  es una condición relativamente débil. Existen conceptos más fuertes de estacionariedad que se derivan y estudian en otros lugares. En particular, se tienen las siguientes definiciones:

% C-estacionario
 \begin{definition}[Punto C-estacionario]
  El punto $z^*$ es: \textit{C-estacionario} si, para cada $j \in J_{GH}$, $\beta_j\gamma_j \geq 0$ se cumple.
\end{definition}
%M-Estacionario
\begin{definition}[Punto M-estacionario]
    El punto $z^*$ es: \textit{M-estacionario} si, para cada $j \in J_{GH}$, o bien $\beta_j,\gamma_j > 0$ $\vee$ $\beta_j \gamma_j = 0$.
\end{definition}
%Fuertemente estacionario
 \begin{definition}[Punto Fuertemente estacionario]
    El punto $z^*$ es: \textit{fuertemente estacionario}  si, para cada $j \in J_{GH}$, $\beta_j, \gamma_j \geq 0$.
\end{definition}


La $C$ y la $M$ estacionariedad  son condiciones necesarias de optimalidad bajo ciertas condiciones de regularidad, más débiles que la  MPEC-LICQ. La fuerte conlleva al siguiente resultado:
% Teorema que si z^* es min local del MPEC Si se cumple la LICQ entonces existe .....
\begin{theorem} 
Sea $z^* \in \mathbb{R}^n$ un mínimo local del MPEC \eqref{eq:DefMpec}. Si MPEC-LICQ se cumple en $z^*$, entonces existe un único multiplicador de Lagrange  tal que $(z^*, \mu, ^*)$ es \textit{fuertemente estacionario}.
\end{theorem}
O sea el punto $z^*$ es un punto estacionario del problema relajado 

\begin{equation}
\begin{array}{cl}
\min  &\quad  f(z)  \\
\text{s.t.} &\quad  g_i(z) \leq 0, \;i=1,\ldots,q, \\ &h_k(z) = 0,\;k=1\ldots,m, \\
&\begin{array}{ccccccccccccccccc}G_j(z) &=& 0, & j\in J_G& G_j(z) &\geq& 0, &j\in J_{GH},& G_j(z) &\geq& 0, & j\in J_H,\\ 
H_j(z) &=& 0, & j\in J_H& H_j(z) &\geq& 0, & j\in J_{GH},& H_j(z) &\geq& 0, & j\in J_G,\end{array}\\
& \text{Problema No Lineal Relajado }  
\end{array}
\label{eRNLP}
\end{equation}Los algoritmos buscan al menos converger a puntos de este tipo.  En la próxima sección se revisarán las reformulaciones que se resuelven  las bibliotecas de Julia.
\section{Métodos de Reformulación para Optimización Binivel}
La optimización binivel presenta desafíos particulares debido a su naturaleza jerárquica y las condiciones de complementariedad resultantes. A continuación, se presentan los principales métodos de reformulación implementados en la literatura, basados en la transformación del MPEC \eqref{eq:KKT_Optimista}.
\subsection{Método Big-M}

El método Big-M (Fortuny-Amat y McCarl)  es una técnica fundamental para reformular problemas de optimización binivel en problemas MPEC. 
Este método aborda específicamente las condiciones de complementariedad que surgen en estas reformulaciones, transformando el problema original en un problema de programación lineal mixta entera (MILP).

La reformulación mediante Big-M introduce un parámetro M suficientemente grande y variables binarias para transformar las condiciones de complementariedad no lineales en restricciones lineales. Para cada condición de complementariedad 
$v_j(x,y)\lambda_j = 0$ en \eqref{eq:KKT_Optimista}, el método introduce una variable binaria  $\delta_j \in \{0,1\}$ y cotas superiores $M_p$, $M_d$ bajo  las siguientes restricciones:

\begin{align}
    v_j(x,y) &\geq -M_p(1 - \delta_j) \notag \\
    \lambda_j &\leq M_d \delta_j \\
	%TODO: EN vez sde f_j poner \delta_j
    \delta_j &\in \{0,1\} \notag
\end{align}

donde $M_p$ y $M_d$ son valores grandes para las variables primales y duales, respectivamente. La efectividad del método depende crucialmente de la selección apropiada de estos valores, que deben ser suficientemente grandes para no excluir la solución óptima, pero no excesivamente grandes para evitar inestabilidades numéricas \cite{BilevelJump}.


\subsection{Método SOS1}

El método de Conjuntos Ordenados Especiales tipo 1 (SOS1) evita el uso de parámetros Big-M mediante restricciones de tipo conjunto. Para cada par complementario $(v_j, \lambda_j)$, $j=1,\ldots, s$:

\begin{equation}\label{eq:SOS1_reform}\begin{matrix}v_j(x,y)=s_j\\
%DONDe SOS1 es v_j * \lambda_j 
[s_j; \lambda_j] \in \text{SOS1} \end{matrix}
\end{equation}
 donde $SOS1=\{(a,b)\in \mathbb{R}: a,b\geq 0,\; ab=0\}$


Esta restricción fuerza que al menos una variable en el par sea cero, preservando la no linealidad original sin necesidad de cotas. Note que SOS1 es un cono. Esta es una reformulación del  MPEC como un problema de optimización conica. Es particularmente eficaz en MPECs con restricciones del tipo $u\in K$, donde $K$ es un cono, pues sigue siendo un problema de optimización cónica  y se pueden aplicar algoritmos específicos para la resolución de este tipo de modelos, \cite{BilevelJump}. La dificultad principal es que el cono es no convexo. Una aplicación de este enfoque se encuentra en \cite{SadddiquiNaturalGasSOS1}.


\subsection{Método ProductMode}

El método ProductMode representa un enfoque directo para manejar las condiciones de complementariedad en su forma de producto original. Este método es particularmente útil cuando se trabaja con solucionadores de programación no lineal (NLP), aunque no garantiza la optimalidad global.

La implementación del ProductMode mantiene la restricción de complementariedad en su forma original:

\begin{equation}
    v_j(x,y) \cdot \lambda_j \leq t \label{eq:ProductMode_reg}
\end{equation}

donde $t > 0$ es un parámetro de regularización pequeño. Esta formulación, aunque no satisface las condiciones de calificación de restricciones estándar, es útil para obtener soluciones iniciales y puede ser especialmente efectiva cuando se combina con solucionadores NLP, ver \cite{BilevelJump}. sin embargo, bajo condiciones naturales, la sucesión que genera converge a puntos C  estacionarios y bajo regularidad hasta fuertemente estacionarios, ver \cite{scholtes12}.  

% TODO: hacer siempre cierre capitulo, y diciendo que se dijo y motivar


La Tabla \ref{tab:comparacion_metodos} resume los requisitos y características de cada método:

\begin{table}[H]
\centering
\begin{tabular}{l|l|l}
\textbf{Método} & \textbf{Solver Requerido} & \textbf{Ventajas} \\ \hline
Big-M & MIP & Estabilidad numérica controlada \\
SOS1 & MIP con SOS1 & Sin parámetros ad-hoc \\
ProductMode & NLP & Manejo de no linealidades \\
\end{tabular}
\caption{Comparación de métodos de reformulación}
\label{tab:comparacion_metodos}
\end{table}

Para casos con restricciones no lineales $v_j(x,y)$, se recomienda combinar ProductMode con técnicas de linealización por tramos \cite[Apéndice B]{BilevelJump}. Todos estos métodos están implementados en BilevelJuMP.jl, permitiendo experimentación con reformulaciones que se pueden encontrar en \cite[Sección 4]{BilevelJump}.


% Se explica de que va BilevelJump
\section{Modelación en Julia}

% Que es Julia
El lenguaje de programación Julia se ha posicionado como una herramienta revolucionaria en el ámbito de la computación científica y la optimización matemática. Desarrollado en el MIT, Julia fue diseñado desde sus cimientos para abordar el denominado "problema de los dos lenguajes", donde tradicionalmente los investigadores se veían obligados a prototipar en un lenguaje de alto nivel como Python y luego reimplementar en C++ o Fortran para obtener rendimiento óptimo. Julia logra combinar la facilidad de uso de lenguajes dinámicos como Python con el rendimiento de lenguajes compilados como C, gracias a su sistema de tipos y su compilador LLVM.
%Usos
Una de las características más destacadas de Julia es su sintaxis expresiva y natural para la formulación matemática. El lenguaje permite escribir código que se asemeja notablemente a las expresiones matemáticas tradicionales, facilitando la traducción directa de modelos matemáticos a código ejecutable. Esta característica es particularmente valiosa en el campo de la optimización, donde la claridad en la expresión de modelos matemáticos es crucial. Julia alcanza velocidades de ejecución comparables a C y Fortran, superando significativamente a Python en cálculos numéricos intensivos, con mejoras de rendimiento que pueden alcanzar órdenes de magnitud en determinadas aplicaciones.
%Uso empresarial
La interoperabilidad de Julia con otros lenguajes de programación constituye una ventaja significativa para proyectos de optimización complejos. A través de paquetes como PyCall, RCall, y JavaCall, Julia puede integrarse perfectamente con bibliotecas establecidas en Python, R y Java. Esta capacidad permite aprovechar el extenso ecosistema de estos lenguajes mientras se mantiene el rendimiento superior de Julia en los cálculos críticos de optimización. Además, Julia puede llamar directamente a funciones de C y Fortran sin overhead adicional, permitiendo la reutilización de código legacy optimizado y la integración con sistemas empresariales existentes.
%Uso en optimización
El ecosistema de optimización en Julia está encabezado por JuMP (Julia for Mathematical Programming), un lenguaje de modelado algebraico embebido que permite expresar problemas de optimización de manera natural y eficiente. JuMP se destaca por su capacidad para manejar problemas de gran escala y su integración perfecta con diversos solucionadores, tanto comerciales como de código abierto. La extensión BilevelJuMP amplía estas capacidades al dominio de la optimización binivel, permitiendo la formulación y resolución de problemas jerárquicos complejos, un área de creciente importancia en la investigación de optimización moderna.

Julia facilita la integración con solucionadores de alto rendimiento como Ipopt para optimización no lineal, SCIP para programación entera mixta, y HiGHS para programación lineal. La interfaz nativa de Julia con estos solucionadores minimiza el overhead de comunicación, resultando en tiempos de resolución significativamente menores comparados con interfaces basadas en Python. Por ejemplo, en problemas de optimización no lineal de gran escala, la combinación de JuMP con Ipopt puede ejecutarse hasta 10 veces más rápido que implementaciones equivalentes en Python utilizando Pyomo o AMPL, lo que demuestra la eficiencia del ecosistema de Julia en aplicaciones prácticas.

La capacidad de Julia para escalar eficientemente en entornos de computación distribuida y GPUs es particularmente relevante para problemas de optimización de gran escala. El lenguaje incluye soporte nativo para computación paralela y distribuida, permitiendo la paralelización de algoritmos de optimización con mínimas modificaciones al código. Paquetes como DistributedArrays y CUDA.jl facilitan la implementación de algoritmos de optimización en clusters y GPUs, respectivamente, manteniendo la sintaxis clara y expresiva característica de Julia.

En el ámbito específico de la optimización matemática, Julia presenta ventajas significativas sobre Python, particularmente en términos de rendimiento y expresividad. Mientras que Python requiere de bibliotecas como Numpy y Scipy para operaciones numéricas eficientes, Julia proporciona estas capacidades de manera nativa. En problemas de optimización complejos, las implementaciones en Julia con JuMP típicamente requieren menos código y se ejecutan más rápidamente que sus equivalentes en Python utilizando Pyomo o CVXPY. Estudios comparativos han demostrado que Julia con JuMP puede resolver problemas de optimización típicos entre 2 y 10 veces más rápido que implementaciones equivalentes en Python, dependiendo de la naturaleza y escala del problema. Esta ventaja se hace más pronunciada en problemas que requieren múltiples evaluaciones de la función objetivo o restricciones complejas, atribuyéndose principalmente a la compilación Just-In-Time de Julia, la ausencia de overhead en la llamada a funciones, y la integración más eficiente con los solucionadores de optimización.

% Que problemas resuelve
Por los argumentos anteriores en este trabajo utilizaremos este lenguaje de programación con principalmente los módulos \textbf{JuMP} y \textbf{BilevelJuMP}, de los cuales se describe a continuación.
% Añadir explicación MPEC
\subsection*{JuMP}
JuMP (Julia for Mathematical Programming) es una biblioteca de modelado algebraico integrada en Julia que permite formular y resolver problemas de optimización matemática de manera eficiente y expresiva. Esta biblioteca está diseñada para abordar problemas de programación matemática que pueden expresarse en la forma general:

\begin{equation}
\min_{z} F(z)
\end{equation}

sa:
\begin{equation}
\begin{aligned}
    & g_i(z) \leq 0, && i = 1,\ldots,q,  \\
    & h_k(z)  = 0, && k = 1,\ldots,q_0,\\
\end{aligned}
\end{equation}

donde \(z \in \mathbb{R}^p \times \mathbb{Z}^{\hat{n}-p}\) representa el vector de variables de decisión, que puede incluir tanto componentes continuos como discretos. La función \(F(z)\) representa el objetivo a minimizar, mientras que \(g_i(z)\) y \(h_k(z)\) representan las restricciones de desigualdad e igualdad, respectivamente.

JuMP proporciona una interfaz intuitiva y matemáticamente rigurosa para la construcción de estos modelos mediante un conjunto de macros especializadas. La macro \textbf{@variable} se utiliza para declarar las variables de decisión, permitiendo especificar su naturaleza (continua o discreta) y sus dominios. Por ejemplo, podemos declarar variables continuas no negativas o variables enteras acotadas. La función objetivo se define mediante la macro \textbf{@objective}, que acepta expresiones lineales, cuadráticas o no lineales. JuMP distingue automáticamente entre estos tipos de expresiones y selecciona los métodos de solución apropiados. La sintaxis es clara y cercana a la notación matemática tradicional, lo que facilita la traducción de modelos matemáticos a código ejecutable. Para la especificación de restricciones, JuMP ofrece dos macros principales: \textbf{@constraint} para restricciones lineales y cuadráticas, y \textbf{@NLconstraint} para restricciones no lineales generales. La biblioteca identifica automáticamente la naturaleza de las restricciones y las procesa de manera eficiente. Las restricciones pueden incluir desigualdades, igualdades y expresiones más complejas que involucren funciones no lineales. Una característica particularmente potente de JuMP es su integración con el paquete \textbf{Complementarity.jl}, que permite la formulación de problemas de complementariedad matemática (MPECs). Esto es especialmente útil para problemas de optimización jerárquica o de equilibrio, donde las condiciones de complementariedad son fundamentales. Las restricciones de complementariedad se pueden expresar de manera natural utilizando la sintaxis proporcionada por estas bibliotecas.

Al resolver un problema de optimización, JuMP proporciona información detallada sobre el estado de la solución mediante un conjunto de estados predefinidos. Estos estados, conocidos como estados primales, permiten interpretar el resultado obtenido. El estado \textbf{NO\_SOLUTION} indica la ausencia de un vector resultado, mientras que \textbf{FEASIBLE\_POINT} confirma la obtención de una solución que satisface todas las restricciones del problema. En casos donde la precisión numérica juega un papel importante, \textbf{NEARLY\_FEASIBLE\_POINT} señala soluciones que son factibles bajo una relajación de las tolerancias en las restricciones. Para problemas que no tienen solución, JuMP puede proporcionar diferentes certificados. El estado \textbf{INFEASIBLE\_POINT} indica que el punto encontrado viola las restricciones, mientras que \textbf{INFEASIBILITY\_CERTIFICATE} proporciona una prueba matemática de que el problema es no factible. En situaciones numéricamente desafiantes, \textbf{NEARLY\_INFEASIBILITY\_CERTIFICATE} representa un certificado de infactibilidad bajo criterios relajados. La biblioteca también puede identificar problemas mal planteados mediante los estados \textbf{REDUCTION\_CERTIFICATE} y \textbf{NEARLY\_REDUCTION\_CERTIFICATE}, que indican la existencia de certificados de mal planteamiento exactos o aproximados, respectivamente. Para casos especiales o no contemplados en las categorías anteriores, se utilizan los estados \textbf{UNKNOWN\_RESULT\_STATUS} y \textbf{OTHER\_RESULT\_STATUS}.

Además, JuMP incorpora la enumeración \textbf{TerminationStatusCode}, que explica la razón por la cual el optimizador dejó de ejecutarse en la última llamada a \textbf{optimize!}. Los posibles valores incluyen: \textbf{OPTIMIZE\_NOT\_CALLED}, cuando el algoritmo no ha comenzado; \textbf{OPTIMAL}, si se encuentra una solución óptima global; \textbf{INFEASIBLE}, cuando el optimizador concluye que no existen soluciones factibles; \textbf{DUAL\_INFEASIBLE}, si no existe una solución dual acotada y, además, se conoce una solución primal, lo que sugiere que el problema es no acotado; \textbf{LOCALLY\_SOLVED}, cuando el algoritmo converge a un punto estacionario o una solución óptima local, pero sin garantías globales; \textbf{LOCALLY\_INFEASIBLE}, si se alcanza un punto no factible sin garantía de que no existan soluciones factibles; \textbf{INFEASIBLE\_OR\_UNBOUNDED}, cuando el optimizador determina que el problema es no factible o no acotado, lo que puede ocurrir en la fase de preprocesamiento; \textbf{ALMOST\_OPTIMAL}, cuando se encuentra una solución óptima global bajo tolerancias relajadas; \textbf{ALMOST\_INFEASIBLE}, si se concluye que no existe una solución factible bajo tolerancias relajadas; \textbf{ALMOST\_DUAL\_INFEASIBLE}, cuando no se encuentra una cota dual válida bajo tolerancias relajadas; \textbf{ALMOST\_LOCALLY\_SOLVED}, si el algoritmo converge a un punto estacionario o solución local dentro de tolerancias relajadas; \textbf{ITERATION\_LIMIT}, si el algoritmo se detiene tras alcanzar el número máximo de iteraciones permitidas; \textbf{TIME\_LIMIT}, cuando el tiempo de ejecución excede el límite definido por el usuario; \textbf{NODE\_LIMIT}, si un algoritmo basado en branch-and-bound explora un número máximo de nodos; \textbf{SOLUTION\_LIMIT}, cuando se alcanza el número requerido de soluciones; \textbf{MEMORY\_LIMIT}, si el optimizador se detiene debido a la falta de memoria; \textbf{OBJECTIVE\_LIMIT}, cuando el algoritmo encuentra una solución mejor que el límite mínimo establecido por el usuario; \textbf{NORM\_LIMIT}, si la norma de un iterado se vuelve demasiado grande; \textbf{OTHER\_LIMIT}, cuando el algoritmo se detiene debido a un límite que no pertenece a las categorías anteriores; \textbf{SLOW\_PROGRESS}, cuando el algoritmo no puede continuar avanzando de manera efectiva hacia la solución; \textbf{NUMERICAL\_ERROR}, si ocurre un error numérico irrecuperable; \textbf{INVALID\_MODEL}, cuando el modelo especificado es inválido; \textbf{INVALID\_OPTION}, si se proporciona una opción de entrada inválida; \textbf{INTERRUPTED}, cuando el algoritmo es interrumpido manualmente; y \textbf{OTHER\_ERROR}, si ocurre un error no contemplado en los estados anteriores.

Una vez que el modelo está completamente especificado, la función \textbf{optimize!} se utiliza para resolver el problema utilizando el solucionador seleccionado. JuMP es compatible con una amplia gama de solucionadores, tanto de código abierto como comerciales, y selecciona automáticamente el más apropiado según la estructura del problema (lineal, cuadrático, no lineal, entero mixto, etc.). Es importante destacar que JuMP maneja eficientemente la diferenciación automática para problemas no lineales, lo que permite calcular gradientes y Hessianas de manera precisa y eficiente, mejorando significativamente el rendimiento y la robustez de los métodos de optimización utilizados.

Para más detalles sobre la biblioteca, ver \cite{JuMPPaper}.
\subsection*{BilevelJuMP}
\textbf{BilevelJuMP.jl} es una extensión especializada de Julia diseñada específicamente para abordar problemas de optimización binivel, también conocidos como problemas de optimización jerárquica o de dos niveles. Esta biblioteca se construye sobre la base de JuMP, aprovechando su sintaxis intuitiva y capacidades de modelado mientras agrega funcionalidades específicas para la formulación y resolución de problemas jerárquicos.
% Decir los de los estatus primales y de terminación 
Además los estados primales y estados de terminación son análogos a los proporcionados por JuMP, manteniendo así la consistencia en la interfaz de programación. Esto significa que los usuarios familiarizados con JuMP encontrarán una experiencia similar al consultar el estado de las soluciones y la terminación de los problemas de optimización binivel.

Este facilita la modelación de esta jerarquía propia de los problemas binivel permitiendo que el problema del seguidor se formule utilizando la sintaxis familiar de JuMP. Esto significa que los usuarios pueden especificar restricciones lineales y cuadráticas, definir variables tanto continuas como enteras, y trabajar con diferentes tipos de funciones objetivo, manteniendo la claridad y expresividad características de JuMP. 

De manera análoga, el problema del nivel superior se gestiona con la misma flexibilidad, permitiendo la especificación de sus propias restricciones y función objetivo.

Una característica notable de BilevelJuMP.jl es su capacidad para manejar diferentes reformulaciones de las restricciones de complementariedad en problemas MPEC (Mathematical Programs with Equilibrium Constraints). Los usuarios pueden experimentar con diversas técnicas de reformulación, incluyendo el método SOS1 (Special Ordered Sets of type 1), la reformulación de McCarl (conocida como Big-M) y ProductMode, descritos anteriormente, adaptando la resolución del problema según las necesidades específicas del caso.

La versatilidad de BilevelJuMP.jl se evidencia en su compatibilidad con diversos tipos de solucionadores. La biblioteca puede utilizar tanto solucionadores de programación lineal mixta entera (MIP) como solucionadores de programación no lineal (NLP), seleccionando el más apropiado según las características particulares del problema y la reformulación elegida. Esta flexibilidad permite abordar una amplia gama de problemas binivel con diferentes estructuras y complejidades.

Sin embargo, es importante reconocer las limitaciones inherentes a BilevelJuMP.jl. Este no permite problemas no convexos, además puede encontrar dificultades al manejar problemas altamente no lineales o con estructuras de optimización particularmente complejas que desafían la representación estándar en la sintaxis de JuMP. Algunas restricciones específicas podrían requerir transformaciones adicionales que incrementan la complejidad del modelo, y en casos de problemas de gran escala, el rendimiento del solucionador puede convertirse en un factor crítico que afecte la eficiencia de la resolución.

Adicionalmente, la formulación y resolución de problemas muy específicos o especializados podría no estar completamente optimizada dentro del paquete, lo que podría requerir adaptaciones o consideraciones especiales por parte del usuario. Estas limitaciones, aunque importantes de considerar, no disminuyen la utilidad general de BilevelJuMP.jl como una herramienta poderosa para la optimización binivel, sino que más bien definen el alcance de su aplicabilidad óptima.

Para más detalles sobre la biblioteca, ver \cite{BilevelJump}.


Teniendo en cuenta la posibilidad de que los métodos de solución converjan a puntos estacionarios de distinto tipo, resulta interesante comprobar si, conocido un punto de esta naturaleza, el algoritmo logra obtener un punto con  mejor evaluación de la función objetivo. Esta es la motivación para el desarrollo del generador de problemas prueba, objeto de esta tesis y que se presentará en el próximo capítulo.

\subsection*{Symbolics}
Symbolics.jl representa un avance significativo en el campo de la computación simbólica dentro del ecosistema de Julia, 
ofreciendo un conjunto robusto de herramientas para la manipulación algebraica y el cálculo simbólico. Esta biblioteca se destaca por su 
capacidad para manejar expresiones matemáticas de manera abstracta, 
permitiendo operaciones como diferenciación, integración y simplificación simbólica con una eficiencia notable. 
El diseño de Symbolics.jl aprovecha las características fundamentales de Julia, como su sistema de tipos y 
compilación JIT, para proporcionar un rendimiento excepcional en comparación con sistemas tradicionales de 
computación simbólica. La biblioteca permite la creación y manipulación de variables simbólicas que pueden 
representar cualquier expresión matemática, implementando capacidades robustas de diferenciación automática 
que incluyen el cálculo de derivadas parciales y totales. Una característica particularmente relevante es su 
sistema de simplificación de expresiones, que utiliza algoritmos avanzados para reducir automáticamente la 
complejidad de expresiones matemáticas extensas. La integración de Symbolics.jl con el resto del ecosistema 
Julia es seamless, lo que facilita su uso en conjunto con otros paquetes orientados al cálculo numérico y 
la resolución de ecuaciones diferenciales. Esta interoperatividad resulta especialmente valiosa en aplicaciones 
que requieren tanto manipulación simbólica como evaluación numérica, como el modelado matemático, el 
análisis numérico y la optimización. 
La biblioteca sobresale en la generación automática de expresiones optimizadas para cálculos numéricos, 
lo que la hace particularmente útil en el contexto de la optimización matemática, donde la eficiencia en la 
evaluación de funciones objetivo y restricciones es crucial. Además, su capacidad para derivar expresiones 
simbólicas de gradientes y hessianas de manera automática la convierte en una herramienta fundamental para 
problemas de optimización que requieren información de derivadas de orden superior.

Para más detalles sobre la biblioteca, ver \cite{SymbolicsPaper}

\subsection*{LinearAlgebra}
LinearAlgebra constituye uno de los módulos fundamentales del núcleo de Julia, 
proporcionando una implementación robusta y eficiente de operaciones de álgebra 
lineal esenciales para la computación científica y la optimización matemática. 
Este módulo se distingue por su capacidad para manejar operaciones matriciales 
complejas con un rendimiento comparable al de bibliotecas altamente optimizadas 
como BLAS y LAPACK, mientras mantiene una sintaxis intuitiva y cercana a la 
notación matemática tradicional. LinearAlgebra implementa una amplia gama de 
operaciones matriciales fundamentales, 
incluyendo descomposiciones matriciales (LU, QR, SVD, Cholesky), 
cálculo de autovalores y autovectores, y operaciones 
básicas como productos matriciales y vectoriales, 
con optimizaciones específicas para diferentes tipos de matrices 
(densas, dispersas, simétricas, triangulares). 
La biblioteca destaca por su sistema de tipos especializados 
que permite representar eficientemente estructuras matriciales específicas, 
como matrices simétricas, hermíticas o triangulares, aprovechando sus 
propiedades matemáticas para optimizar tanto el almacenamiento como las 
operaciones computacionales. Una característica particularmente relevante 
es su integración natural con el sistema de despacho múltiple de Julia, 
que permite que las operaciones se optimicen automáticamente según los 
tipos de datos involucrados, resultando en un rendimiento excepcional sin 
sacrificar la claridad del código. Esta eficiencia es crucial en el contexto 
de la optimización matemática, donde las operaciones de álgebra lineal son 
frecuentemente el cuello de botella computacional en la evaluación de funciones 
objetivo y restricciones. Además, el módulo proporciona funcionalidades 
avanzadas como la factorización de matrices dispersas y el cálculo de normas 
matriciales, que son esenciales en algoritmos de optimización numérica y 
métodos iterativos de resolución de sistemas lineales.

Para más detalles sobre la biblioteca, ver \cite{LinearAlgebraJL}
