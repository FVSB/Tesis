
\chapter{Experimentación}


En este capítulo se presenta la fase experimental basada en una selección de problemas de optimización binivel extraídos de la literatura especializada \cite{BolibTestProblems}. El estudio abarca tres categorías fundamentales de problemas: Lineales, Cuadráticos y No Convexos. La metodología experimental se desarrollará mediante la utilización de las bibliotecas de Julia para la identificación de mínimos locales, seguida de la perturbación de estos puntos mediante la introducción de valores aleatorios. A partir de estas modificaciones, se procederá a la generación de problemas estacionarios clasificados en 4 tipos específicos: $\alpha = 0$, \textit{C}, \textit{M} y \textit{fuerte}

Los problemas modificados serán posteriormente evaluados utilizando algoritmos tradicionales implementados en Julia, con el objetivo de analizar su eficacia en relación al valor de la función objetivo del nivel superior. Este proceso permitirá determinar el impacto de las modificaciones realizadas y la robustez de los algoritmos frente a las variaciones introducidas.

Para garantizar un análisis exhaustivo y representativo, se han seleccionado un total de quince problemas de optimización binivel, distribuidos equitativamente entre las tres categorías mencionadas, asignando cinco problemas a cada una de ellas. Los problemas correspondientes a las categorías Lineales y Cuadráticos han sido extraídos de \cite{Floudas1999HandbookOT}, mientras que los problemas No Convexos provienen de \cite{BolibTestProblems}. Esta selección diversa permite una evaluación comprehensiva de las diferentes características y comportamientos de los problemas de optimización binivel bajo estudio.



\section{Modelación de la experimentación}
En esta sección se describe el proceso de experimentación, donde se toman las siguientes consideraciones. 
Todos los valores, han sido redondeados por exceso a dos cifras decimales. 
Los problemas escogidos para la experimentación son:

%Tabla con los problemas escogidos
\begin{table}[H]
\centering
\caption{Problemas Seleccionados}
\begin{tabular}{ | m{5cm} | m{5cm} | m{5cm} | }
  
  \hline
  \textbf{No Convexos} & \textbf{Lineales} & \textbf{Cuadráticos} \\
  \hline
  MitsosBarton2006Ex312 & ex9.1.1 & ex9.2.1 \\
  \hline
  MitsosBarton2006Ex313 & ex9.1.2 & ex9.2.2 \\
  \hline
  MitsosBarton2006Ex314 & ex9.1.8 & ex9.2.3\\
  \hline
  MitsosBarton2006Ex323 & ex9.1.9 & ex9.2.4\\
  \hline
  MorganPatrone2006a & ex9.1.10 & ex9.2.5 \\
  \hline
\end{tabular}
\end{table}

Inicialmente se computan óptimos de los problemas con los paquetes convencionales de Julia
cuya forma de resolver dependerá de la clase del problema. A continuación definiremos cada tipo de clase y como se obtienen los óptimos. 

% Definir problemas lineales

\begin{itemize}
    \item \textbf{Problemas Lineales y Cuadráticos :}\\
            Un problema binivel lineal es aquel en el cual los problemas del nivel superior e inferior son lineales, análogamente se define el problema cuadrático.
            % Escribir la definición matemática
            
            Con dicho problema se introducen los datos en la interfaz de \textbf{BilevelJuMP}, ver \cite{BilevelJump}, con el cual se utilizan 3 técnicas entre las ofrecidas por esta:
            \begin{itemize}
                \item \textbf{Big-M :} Con el optimizador High-Performance Solver for Linear Programming (HiGHS) y los valores $\text{primal big M} = 100, \quad \text{dual big M} = 100$.
                \item \textbf{SOS1 :} Con el optimizador Solving Constraint Integer Programs (SCIP).
                \item \textbf{ProductMode :} Con el optimizador Interior Point Optimizer (Ipopt).
            \end{itemize} 
            Cada uno de los resultados de evaluar el problema en cada forma anterior se guardan en un formato \textit{.xlsx}
            donde por cada optimizador se guardan los parámetros:
            \begin{itemize}
                \item Estatus del Primal, el cual define si es un punto factible o no.
                \item Estatus de la Finalización, si terminó porque encontró un óptimo o se estancó en un óptimo local.
                \item Valor de la función objetivo del nivel superior.
                \item El punto óptimo encontrado, en caso de ser hallado.
                \item El tiempo de ejecución.
            \end{itemize} 
            Posteriormente se analizan los resultados de dichos métodos, se selecciona el de mejor evaluación de la función objetivo.
    \item \textbf{Problemas No Convexos :}\\
            Al \textbf{BilevelJuMP} no contar con soporte para esta clase de problemas se utiliza \textbf{JuMP}, ver \cite{JuMPPaper}.
            Por ello se utiliza la reformulación KKT como la de \ref{eq:KKT_Optimista} y se procede a utilizar la interfaz brindada por este. Para el caso de las restricciones de 
            complementariedad se utiliza \textbf{Complementarity}, ver \cite{Complementarityjl}, con el optimizador Ipopt y análogo al caso anterior se extraen los mismos datos.
\end{itemize}


\subsubsection{Generación de los problemas}
Para la generación de los problemas, se toman los problemas seleccionados anteriormente con su punto óptimo calculado por las bibliotecas antes dichas, para ello mediante código de Julia se procede a generar los 4 tipos de problemas modificados: con \textit{$\alpha =0 $}, \textit{C-Estacionario}, \textit{M-Estacionario} y \textit{Fuertemente Estacionario}, mediante 
código de Julia para dichos experimentos. Cada experimento se realizará con semillas para poder replicarlos, cuya asignación se muestran en las tablas siguientes:



\begin{table}[h!]
\centering
\caption{Semillas utilizadas en problemas Lineales}
\begin{tabular}{ | m{5cm} | m{5cm} | m{5cm} | }
  
  \hline
  \textbf{No Convexos} & \textbf{Valor de la semilla para generar los problemas}  & \textbf{Valor de la semilla para hallar los óptimos de cada problema modificado} \\
  \hline
 ex9.1.1 & 20 & 6 \\
  \hline
 ex9.1.2 & 2 & 8\\
  \hline
   ex9.1.8 & 3& 9 \\
  \hline
  ex9.1.9 & 4 & 10\\
  \hline
 ex9.1.10 & 5 & 7 \\
  \hline
\end{tabular}
\end{table}


\begin{table}[h!]
    \centering
    \caption{Semillas utilizadas en problemas Cuadráticos}
    \begin{tabular}{ | m{5cm} | m{5cm} | m{5cm} | }
      
      \hline
      \textbf{No Convexos} & \textbf{Valor de la semilla para generar los problemas}  & \textbf{Valor de la semilla para hallar los óptimos de cada problema modificado} \\
      \hline
      ex9.2.1 & 11 &11 \\
      \hline
      ex9.2.2 & 12 &12 \\
      \hline
      ex9.2.3 & 13 &13\\
      \hline
      ex9.2.4 & 14 &14\\
      \hline
      ex9.2.5 & 15 &15\\
      \hline
    \end{tabular}
    \end{table}

    \begin{table}[h!]
        \centering
        \caption{Semillas utilizadas en problemas No Convexos}
        \begin{adjustbox}{max width=\textwidth}
        \begin{tabular}{ | m{5cm} | m{5cm} | m{5cm} | }
          
          \hline
          \textbf{No Convexos} & \textbf{Valor de la semilla para generar los problemas}  & \textbf{Valor de la semilla para hallar los óptimos de cada problema modificado} \\
          \hline
          MitsosBarton2006Ex312 & 6  & 1\\
          \hline
          MitsosBarton2006Ex313 & 7 & 2 \\
          \hline
          MitsosBarton2006Ex314 & 9 & 3\\
          \hline
          MitsosBarton2006Ex323 & 10 & 4\\
          \hline
          MorganPatrone2006a & 11 & 5 \\
          \hline
        \end{tabular}
     \end{adjustbox}
    \end{table}

    \section{Metodología de Generación y Experimentación}
    % Aclarar que son replicable
    % Aclarar que se divide en generar problemas, esos problemas guardarlos, después mandarlos a Julia a ver como rinden
    La experimentación consta de 3 partes fundamentales: generación del problema perturbado (para cumplir con cierta clase de estacionariedad en un punto dado), cómputo de óptimos del problema, análisis de los resultados.

    %
    Para la generación de los diferentes tipos de problemas perturbados utiliza semillas para la generación de los valores aleatorios para una replicación del mismo.
    La implementación sigue una sintaxis similar a la descrita en el capítulo anterior, dado que esta nueva implementación incorpora y extiende la anterior, pero permite 
    que con solo introducir un problema base se puedan generar los 4 tipos de problemas perturbados.
    
    El proceso de modificación de los puntos comienza con el problema original de entrada y el punto obtenido previamente. A cada componente de este punto se le añade un valor aleatorio en el intervalo $[5e-10, 5]$, obteniendo así el punto modificado $z^*_0$. Para los casos donde $\vec{\alpha}\neq \vec{0}$, se genera un vector aleatorio con componentes en el intervalo $[3e-10, 3]$. En cuanto a los conjuntos de índices activos de las $v_{j}s$, estos se distribuyen siguiendo una proporción específica: $1/2$ corresponde al tipo $J_1^v$ (\ref{J_0_lambda_0_level_inferior}), mientras que el $1/4$ restante se divide entre los tipos \ref{J_0_lambda_pos_level_inferior} y \ref{J_neg_lambda_0_level_inferior}.
    
    La selección de los multiplicadores $\lambda_j$ $\beta_j$ y $\gamma_j$ se realiza mediante la generación de valores aleatorios en el intervalo $[1e-2, 10]$ cuando estos no deben ser $0$. En los casos donde existen múltiples combinaciones posibles de multiplicadores con respecto a su igualdad a $0$, se utiliza una distribución uniforme discreta para la selección aleatoria.
    
    Cada problema generado se almacena en un archivo \textit{.xlsx} siguiendo la nomenclatura: \textit{(nombre del problema)\_(Tipo de punto estacionario)(generator)\_alpha\_((non\_zero) si $\alpha \neq 0$ y (zero) si $\alpha = 0$).xlsx}. Este archivo contiene la información completa del problema, incluyendo las expresiones de las funciones objetivo de ambos niveles con sus evaluaciones en el punto, las restricciones de ambos niveles con sus respectivos multiplicadores y tipos de índices activos, el punto $z^*_0$, los vectores $\vec{bf}$ y $\vec{BF}$, y el multiplicador $\vec{\alpha}$.
    
    La compilación y procesamiento posterior se realiza mediante un script de Python que utiliza las dependencias \textit{pandas} y \textit{sympy}. Este script procesa la información contenida en los archivos \textit{.xlsx} y genera scripts \textit{.jl} con el módulo de experimentación para la obtención de valores óptimos. La ejecución de estos scripts se gestiona mediante \textit{subprocess}, y los resultados se recopilan para identificar los casos más relevantes y generar tanto el código latex de cada problema modificado como las tablas de resultados correspondientes.
    
    %Análisis Comparativo de Algoritmos
    
    %Presentación de Resultados
    Los resultados seleccionados se presentan en tablas estructuradas que incluyen información fundamental para cada problema, hay una por cada tipo de problema y tipo de punto lo que hace una total de 12. Estas tablas contienen el nombre del problema original que fue modificado para alcanzar la estacionariedad de la clase deseada, el punto al cual se forzó ser estacionario de la clase requerida (asegurando que no pertenezca a un subconjunto de esta), la evaluación de la función objetivo en el punto estacionario, el punto óptimo identificado por los algoritmos de Julia, la evaluación de la función objetivo en este óptimo, el método seleccionado para su obtención y el tiempo requerido para su ejecución. Además al final de cada tipo de problema existe una tabla la cual por cada tipo de punto se pone un problema característico el cual obtuvo mejor evaluación de la función objetivo con respecto al del mejor óptimo.



\subsection{Problemas Lineales} 
  

\subsubsection{$\alpha =0$}
La tabla con los resultados de estos tipos de problema es \ref{result:linear_alpha_zero}.


En los problemas de Alpha Zero, se mostró cierta complejidad para SOS1, el cual en algunos casos no pudo determinar puntos, mientras que Big-M logró completar los objetivos. 
Los puntos hallados en los problemas eran mayoritariamente distantes en sus componentes con respecto al punto estacionario original,  indicando que el posible valor óptimo no está en una vecindad del punto inicial, siendo la diferencia de componente a componente, tan grande como $1e+20$.
En términos generales de rendimiento, Big-M tuvo un excelente desempeño, seguido de SOS1 y por último de ProductMode. 
En este caso el problema que mayor mejora tuvo fue el ex9.1.1



\subsubsection{C-Estacionario}
La tabla con los resultados de estos tipos de problema es \ref{result:linear_c_estacionario}.
 
En los problemas de C-Estacionario donde la evaluación del punto estacionario inicial es 0, no mejoró el valor de la función objetivo evaluada en el óptimo. El método Big-M tuvo problemas para hallar el óptimo, probablemente debido a los valores extremos de este.
 

 

\subsubsection{M-Estacionario}
La tabla con los resultados de estos tipos de problema es \ref{result:linear_m_estacionario}.

En los problemas de M-Estacionario, los algoritmos tuvieron grandes dificultades para encontrar el óptimo. 
Los problemas ex9.1.10 y ex9.1.9 son los únicos en los que Julia halló puntos óptimos, en el primero halló un punto óptimo cuya evaluación es cercana a la del punto estacionario inicial aunque sin estar en una vecindad de este, el segundo halló mediante Big-M y SOS1 puntos óptimos que están en la vecindad del punto estacionario inicial y  ProductMode localizó un punto óptimo cuya evaluación es igual a la evaluación del punto estacionario inicial aunque este no se encuentra en una vecindad. ProductMode tuvo complicaciones para hallar los óptimos en este tipo de problemas.
 
  
\subsubsection{Fuertemente Estacionario}
La tabla con los resultados de estos tipos de problema es \ref{result:linear_fuertemente_estacionario}.
    
 En los problemas de tipo Fuertemente Estacionario, los métodos de Julia presentaron complicaciones  en  ex9.1.1 y ex9.1.9 donde en ambos casos Big-M, SOS1 y ProductMode hallaron puntos óptimos en la vecindad del punto estacionario inicial.



\subsubsection{Problemas relevantes de cada categoría de punto}

La tabla con los resultados de estos tipos de problema es \ref{result:linear_resultados_seleccionados}.

En los problemas analizados se evidencia que mientras más fuertes sean las condiciones de los puntos es más probable de hallar óptimos en la vecindad del punto original, 
así como también es probable que los algoritmos no logren encontrar un valor óptimo y terminen con puntos insatisfactibles.
El método SOS1 tuvo dificultades para obtener alguna solución, mientras que Big-M tuvo mayormente problemas asociados a sus valores extremos, teniendo ProductMode un comportamiento similar a este aunque con mayor tiempo de cómputo.
Además no existe caso en el que el valor objetivo halla sido peor que el valor inicial estacionario.
   

o

\subsection{Problemas Cuadráticos}


%region Resultados Cuadráticos
\subsubsection{$\alpha =0$}
La tabla con los resultados de estos tipos de problema es \ref{result:cuadraticos_alpha_zero}.

En los problemas ex9.2.3 y ex9.2.4, los métodos encontraron puntos cuyo valor de la función objetivo es considerablemente peor que el del punto estacionario inicial. 
En estos casos, los puntos óptimos propuestos son los mismos, lo que sugiere que este tipo de punto puede causar perturbaciones en los métodos para hallar óptimos. 
Los dos problemas restantes no lograron encontrar un valor óptimo considerablemente menor al del valor objetivo en el punto estacionario inicial. 
Sin embargo, los métodos lograron obtener supuestos óptimos en todos los problemas.
    
\subsubsection{C-Estacionario}   
La tabla con los resultados de estos tipos de problema es \ref{result:cuadraticos_c_estacionario}.

En estos tipos de puntos los problemas ex9.2.1 y ex.9.2.4 obtuvieron peor evaluación del óptimo propuesto que el del punto estacionario inicial en SOS1 y ProductMode, 
en ellos Big-M no pudo entregar ningún resultado. En el resto de problemas se obtuvieron puntos óptimos en vecindades cercanas y con evaluación cercana al punto estacionario original,
excepto en ex9.2.3 que los 3 métodos lograron encontrar puntos óptimos que aunque no se encuentran en la vecindad del punto estacionario inicial sus evaluaciones mejoran a la de este.


    
\subsubsection{M-Estacionario}
La tabla con los resultados de estos tipos de problema es \ref{result:cuadraticos_m_estacionario}.  

En estos problemas no se obtuvo ninguna mejora significativa. 
En los problemas ex9.2.2 y ex9.2.4, se encontró un punto distante del punto estacionario original, tanto componente a componente como en su evaluación. 
El resto de los problemas obtuvieron puntos cercanos al original. 
En todos los problemas, los métodos que devolvieron algún valor lograron encontrar un candidato a óptimo.
    
\subsubsection{Fuertemente Estacionario}
La tabla con los resultados de estos tipos de problema es \ref{result:cuadraticos_fuertmente_estacionario}.   

En los problemas ex9.2.2 y ex9.2.4 no se lograron obtener puntos óptimos, mientras que en el ex9.2.3 se logró una mejora considerable en los tres métodos, 
constatando que Big-M es el método más rápido de solución.

\subsubsection{Problemas relevantes de cada categoría de punto:}
La tabla con los resultados de estos tipos de problema es \ref{result:cuadraticos_seleccionados}.

En este tipo de problemas excepto en el caso fuertemente estacionario no se encontraron dificultades en los algoritmos para encontrar un punto óptimo. Existe una mejora entre los tipos de puntos con condiciones más fuertes respecto a que el óptimo hallado por Julia se encuentre en una vecindad del punto estacionario inicial. 

%endregion
\subsection{Problemas No Convexos}


%region Problemas No Convexos
\subsubsection{$\alpha =0$}
La tabla con los resultados de estos tipos de problema es \ref{result:no_convexos_alpha_zero}.

 En este tipo de puntos, las soluciones halladas por Julia coinciden con el punto inicial, excepto en el problema MitsosBarton2006Ex323.
    
\subsubsection{C-Estacionario}
La tabla con los resultados de estos tipos de problema es \ref{result:no_convexos_c_estacionario}.

 En este tipo de problemas, las soluciones halladas por Julia empeoran en los problemas MitsosBarton2006Ex313 y MitsosBarton2006Ex314, aun teniendo el valor de las variables del nivel superior iguales al punto estacionario inicial. Además, en MorganPatrone2006a no fue posible hallar el óptimo.
\subsubsection{M-Estacionario}
La tabla con los resultados de estos tipos de problema es \ref{result:no_convexos_m_estacionario}.  

 En este tipo de puntos, solo obtuvieron solución los problemas MitsosBarton2006Ex313 y MitsosBarton2006Ex314, obteniendo en ambos casos peores resultados del valor óptimo hallado por Julia en comparación con el valor del punto estacionario inicial, aunque los puntos coinciden en las variables del nivel superior.
    
\subsubsection{Fuertemente Estacionario}
La tabla con los resultados de estos tipos de problema es \ref{result:no_convexos_fuertemente_estacionario}.

 En este tipo de puntos, excepto en el problema MitsosBarton2006Ex323,
 se obtuvieron puntos óptimos, 
 los cuales solo mejoran levemente su valor en MitsosBarton2006Ex312. 
 Además, en todos los casos, los valores de las variables del nivel superior coinciden.
     

\subsubsection{Problemas relevantes de cada categoría de punto:}
La tabla con los resultados de estos tipos de problema es \ref{result:no_convexos_seleccionados}.

Después de analizar los puntos en este tipo de problemas, los resultados brindan información que sugiere que, mientras más fuertes son las condiciones del punto, los algoritmos no encuentran puntos óptimos mejores que el estacionario inicial. Esto parece deberse a que, por la propia reformulación del problema, es más probable que no se pueda optimizar correctamente el problema del nivel inferior. Además, la tendencia indica que, mientras más fuertes sean las condiciones del punto, es más probable que las variables del nivel superior coincidan en el punto óptimo hallado por Julia y el punto estacionario inicial.
  


\subsection{Análisis de los resultados}


El análisis de los experimentos realizados en este capítulo permite observar distintos comportamientos según el tipo de problema analizado.
%Lineales 
En los problemas lineales, se evidenció que, a medida que se imponen condiciones más fuertes en los puntos, aumenta la probabilidad de hallar óptimos en la vecindad del punto original. 
Sin embargo, estas mismas condiciones también incrementan la posibilidad de que los algoritmos no logren encontrar una solución óptima y terminen en puntos insatisfactibles. 
En particular, el método SOS1 presentó dificultades para obtener alguna solución, mientras que el método Big-M mostró problemas asociados a valores extremos. 
Un comportamiento similar se observó en ProductMode, aunque este último requirió un mayor tiempo de cómputo. 
Cabe destacar que en ningún caso el valor objetivo fue peor que el valor inicial estacionario.  

% Cuadráticos
En los problemas cuadráticos, los algoritmos en general no presentaron dificultades para encontrar puntos óptimos, salvo en los casos de condiciones fuertemente estacionarias. 
Se observó una mejora en la coincidencia entre el punto óptimo y el punto estacionario inicial cuando las condiciones eran más estrictas. 
No obstante, en el caso de condiciones fuertemente estacionarias, esta tendencia podría deberse a la naturaleza de estos problemas, 
lo que sugiere que los métodos implementados en Julia podrían enfrentar dificultades en dichos escenarios. 
 
% No convexos
En el caso de los problemas no convexos, los resultados indican que, a medida que las condiciones del punto se fortalecen, 
los algoritmos tienden a no encontrar puntos óptimos superiores al estacionario inicial. 
Esto parece estar relacionado con la propia reformulación del problema, 
que dificulta la optimización del nivel inferior. 
Además, se observó una tendencia en la que, al aumentar la fortaleza de las condiciones del punto, 
es más probable que las variables del nivel superior coincidan entre el punto óptimo hallado por Julia y 
el punto estacionario inicial.  

En conclusión, los resultados de los experimentos muestran que la fortaleza de las condiciones impuestas 
sobre los puntos tiene un impacto significativo en el desempeño de los algoritmos de optimización. 
Cada tipo de problema presenta comportamientos diferenciados, lo que sugiere la necesidad de considerar 
cuidadosamente estas condiciones al aplicar métodos de optimización en distintos contextos.
