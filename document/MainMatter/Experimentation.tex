
\chapter{Experimentación}


En este capítulo se presenta la fase experimental basada en una selección de problemas de optimización binivel extraídos de la literatura especializada \cite{BolibTestProblems}. El estudio abarca tres categorías fundamentales de problemas: Lineales, Cuadráticos y No Convexos. La metodología experimental se desarrollará mediante la utilización de las bibliotecas de Julia para la identificación de mínimos locales, seguida de la perturbación de estos puntos mediante la introducción de valores aleatorios. A partir de estas modificaciones, se procederá a la generación de problemas estacionarios clasificados en 4 tipos específicos: $\alpha = 0$, \textit{C}, \textit{M} y \textit{fuerte}

Los problemas modificados serán posteriormente evaluados utilizando algoritmos tradicionales implementados en Julia, con el objetivo de analizar su eficacia en relación al valor de la función objetivo del nivel superior. Este proceso permitirá determinar el impacto de las modificaciones realizadas y la robustez de los algoritmos frente a las variaciones introducidas.

Para garantizar un análisis exhaustivo y representativo, se han seleccionado un total de quince problemas de optimización binivel, distribuidos equitativamente entre las tres categorías mencionadas, asignando cinco problemas a cada una de ellas. Los problemas correspondientes a las categorías Lineales y Cuadráticos han sido extraídos de \cite{Floudas1999HandbookOT}, mientras que los problemas No Convexos provienen de \cite{BolibTestProblems}. Esta selección diversa permite una evaluación comprehensiva de las diferentes características y comportamientos de los problemas de optimización binivel bajo estudio.



\section{Modelación de la experimentación}
En esta sección se describe el proceso de experimentación, donde se toman las siguientes consideraciones. 
Todos los valores, han sido redondeados por exceso a dos cifras decimales. 
Los problemas escogidos para la experimentación son:

%Tabla con los problemas escogidos
\begin{table}[H]
\centering
\caption{Problemas Seleccionados}
\begin{tabular}{ | m{5cm} | m{5cm} | m{5cm} | }
  
  \hline
  \textbf{No Convexos} & \textbf{Lineales} & \textbf{Cuadráticos} \\
  \hline
  MitsosBarton2006Ex312 & ex9.1.1 & ex9.2.1 \\
  \hline
  MitsosBarton2006Ex313 & ex9.1.2 & ex9.2.2 \\
  \hline
  MitsosBarton2006Ex314 & ex9.1.8 & ex9.2.3\\
  \hline
  MitsosBarton2006Ex323 & ex9.1.9 & ex9.2.4\\
  \hline
  MorganPatrone2006a & ex9.1.10 & ex9.2.5 \\
  \hline
\end{tabular}
\end{table}

Inicialmente se computan óptimos de los problemas con los paquetes convencionales de Julia
cuya forma de resolver dependerá de la clase del problema. A continuación definiremos cada tipo de clase y como se obtienen los óptimos. 

% Definir problemas lineales

\begin{itemize}
    \item \textbf{Problemas Lineales y Cuadráticos :}\\
            Un problema binivel lineal es aquel en el cual los problemas del nivel superior e inferior son lineales, análogamente se define el problema cuadrático.
            % Escribir la definición matemática
            
            Con dicho problema se introducen los datos en la interfaz de \textbf{BilevelJuMP}, ver \cite{BilevelJump}, con el cual se utilizan 3 técnicas entre las ofrecidas por esta:
            \begin{itemize}
                \item \textbf{Big-M :} Con el optimizador High-Performance Solver for Linear Programming (HiGHS) y los valores $\text{primal big M} = 100, \quad \text{dual big M} = 100$.
                \item \textbf{SOS1 :} Con el optimizador Solving Constraint Integer Programs (SCIP).
                \item \textbf{ProductMode :} Con el optimizador Interior Point Optimizer (Ipopt).
            \end{itemize} 
            Cada uno de los resultados de evaluar el problema en cada forma anterior se guardan en un formato \textit{.xlsx}
            donde por cada optimizador se guardan los parámetros:
            \begin{itemize}
                \item Estatus del Primal, el cual define si es un punto factible o no.
                \item Estatus de la Finalización, si terminó porque encontró un óptimo o se estancó en un óptimo local.
                \item Valor de la función objetivo del nivel superior.
                \item El punto óptimo encontrado, en caso de ser hallado.
                \item El tiempo de ejecución.
            \end{itemize} 
            Posteriormente se analizan los resultados de dichos métodos, se selecciona el de mejor evaluación de la función objetivo.
    \item \textbf{Problemas No Convexos :}\\
            Al \textbf{BilevelJuMP} no contar con soporte para esta clase de problemas se utiliza \textbf{JuMP}, ver \cite{JuMPPaper}.
            Por ello se utiliza la reformulación KKT como la de \ref{eq:KKT_Optimista} y se procede a utilizar la interfaz brindada por este. Para el caso de las restricciones de 
            complementariedad se utiliza \textbf{Complementarity}, ver \cite{Complementarityjl}, con el optimizador Ipopt y análogo al caso anterior se extraen los mismos datos.
\end{itemize}


\subsubsection{Generación de los problemas}
Para la generación de los problemas, se toman los problemas seleccionados anteriormente con su punto óptimo calculado por las bibliotecas antes dichas, para ello mediante código de Julia se procede a generar los 4 tipos de problemas modificados: con \textit{$\alpha =0 $}, \textit{C-Estacionario}, \textit{M-Estacionario} y \textit{Fuertemente Estacionario}, mediante 
código de Julia para dichos experimentos. Cada experimento se realizará con semillas para poder replicarlos, cuya asignación se muestran en las tablas siguientes:



\begin{table}[h!]
\centering
\caption{Semillas utilizadas en problemas Lineales}
\begin{tabular}{ | m{5cm} | m{5cm} | m{5cm} | }
  
  \hline
  \textbf{No Convexos} & \textbf{Valor de la semilla para generar los problemas}  & \textbf{Valor de la semilla para hallar los óptimos de cada problema modificado} \\
  \hline
 ex9.1.1 & 20 & 6 \\
  \hline
 ex9.1.2 & 2 & 8\\
  \hline
   ex9.1.8 & 3& 9 \\
  \hline
  ex9.1.9 & 4 & 10\\
  \hline
 ex9.1.10 & 5 & 7 \\
  \hline
\end{tabular}
\end{table}


\begin{table}[h!]
    \centering
    \caption{Semillas utilizadas en problemas Cuadráticos}
    \begin{tabular}{ | m{5cm} | m{5cm} | m{5cm} | }
      
      \hline
      \textbf{No Convexos} & \textbf{Valor de la semilla para generar los problemas}  & \textbf{Valor de la semilla para hallar los óptimos de cada problema modificado} \\
      \hline
      ex9.2.1 & 11 &11 \\
      \hline
      ex9.2.2 & 12 &12 \\
      \hline
      ex9.2.3 & 13 &13\\
      \hline
      ex9.2.4 & 14 &14\\
      \hline
      ex9.2.5 & 15 &15\\
      \hline
    \end{tabular}
    \end{table}

    \begin{table}[h!]
        \centering
        \caption{Semillas utilizadas en problemas No Convexos}
        \begin{adjustbox}{max width=\textwidth}
        \begin{tabular}{ | m{5cm} | m{5cm} | m{5cm} | }
          
          \hline
          \textbf{No Convexos} & \textbf{Valor de la semilla para generar los problemas}  & \textbf{Valor de la semilla para hallar los óptimos de cada problema modificado} \\
          \hline
          MitsosBarton2006Ex312 & 6  & 1\\
          \hline
          MitsosBarton2006Ex313 & 7 & 2 \\
          \hline
          MitsosBarton2006Ex314 & 9 & 3\\
          \hline
          MitsosBarton2006Ex323 & 10 & 4\\
          \hline
          MorganPatrone2006a & 11 & 5 \\
          \hline
        \end{tabular}
     \end{adjustbox}
    \end{table}

    \section{Metodología de Generación y Experimentación}
    % Aclarar que son replicable
    % Aclarar que se divide en generar problemas, esos problemas guardarlos, después mandarlos a Julia a ver como rinden
    La experimentación consta de 3 partes fundamentales: generación del problema perturbado (para cumplir con cierta clase de estacionariedad en un punto dado), cómputo de óptimos del problema, análisis de los resultados.

    %
    Para la generación de los diferentes tipos de problemas perturbados utiliza semillas para la generación de los valores aleatorios para una replicación del mismo.
    La implementación sigue una sintaxis similar a la descrita en el capítulo anterior, dado que esta nueva implementación incorpora y extiende la anterior, pero permite 
    que con solo introducir un problema base se puedan generar los 4 tipos de problemas perturbados.
    
    El proceso de modificación de los puntos comienza con el problema original de entrada y el punto obtenido previamente. A cada componente de este punto se le añade un valor aleatorio en el intervalo $[5e-10, 5]$, obteniendo así el punto modificado $z^*_0$. Para los casos donde $\vec{\alpha}\neq \vec{0}$, se genera un vector aleatorio con componentes en el intervalo $[3e-10, 3]$. En cuanto a los conjuntos de índices activos de las $v_{j}s$, estos se distribuyen siguiendo una proporción específica: $1/2$ corresponde al tipo $J_1^v$ (\ref{J_0_lambda_0_level_inferior}), mientras que el $1/4$ restante se divide entre los tipos \ref{J_0_lambda_pos_level_inferior} y \ref{J_neg_lambda_0_level_inferior}.
    
    La selección de los multiplicadores $\lambda_j$ $\beta_j$ y $\gamma_j$ se realiza mediante la generación de valores aleatorios en el intervalo $[1e-2, 10]$ cuando estos no deben ser $0$. En los casos donde existen múltiples combinaciones posibles de multiplicadores con respecto a su igualdad a $0$, se utiliza una distribución uniforme discreta para la selección aleatoria.
    
    Cada problema generado se almacena en un archivo \textit{.xlsx} siguiendo la nomenclatura: \textit{(nombre del problema)\_(Tipo de punto estacionario)(generator)\_alpha\_((non\_zero) si $\alpha \neq 0$ y (zero) si $\alpha = 0$).xlsx}. Este archivo contiene la información completa del problema, incluyendo las expresiones de las funciones objetivo de ambos niveles con sus evaluaciones en el punto, las restricciones de ambos niveles con sus respectivos multiplicadores y tipos de índices activos, el punto $z^*_0$, los vectores $\vec{bf}$ y $\vec{BF}$, y el multiplicador $\vec{\alpha}$.
    
    La compilación y procesamiento posterior se realiza mediante un script de Python que utiliza las dependencias \textit{pandas} y \textit{sympy}. Este script procesa la información contenida en los archivos \textit{.xlsx} y genera scripts \textit{.jl} con el módulo de experimentación para la obtención de valores óptimos. La ejecución de estos scripts se gestiona mediante \textit{subprocess}, y los resultados se recopilan para identificar los casos más relevantes y generar tanto el código latex de cada problema modificado como las tablas de resultados correspondientes.
    
    %Análisis Comparativo de Algoritmos
    
    %Presentación de Resultados
    Los resultados seleccionados se presentan en tablas estructuradas que incluyen información fundamental para cada problema, hay una por cada tipo de problema y tipo de punto lo que hace una total de 12. Estas tablas contienen el nombre del problema original que fue modificado para alcanzar la estacionariedad de la clase deseada, el punto al cual se forzó ser estacionario de la clase requerida (asegurando que no pertenezca a un subconjunto de esta), la evaluación de la función objetivo en el punto estacionario, el punto óptimo identificado por los algoritmos de Julia, la evaluación de la función objetivo en este óptimo, el método seleccionado para su obtención y el tiempo requerido para su ejecución. Además al final de cada tipo de problema existe una tabla la cual por cada tipo de punto se pone un problema característico el cual obtuvo mejor evaluación de la función objetivo con respecto al del mejor óptimo.



\subsection{Problemas Lineales} 
  

\subsubsection{$\alpha =0$}
%La tabla con los resultados de estos tipos de problema es \ref{result:linear_alpha_zero}.

En todos problemas lineales cuyos multiplicador $\alpha=0$ existió solución óptima 
por parte de los métodos de Julia, en 3 de ellos el valor del óptimo fue capaz de mejorar el valor de la función objetivo en el punto estacionario inicial donde Big-M fue el que obtuvo el de menor valor en cada uno, que coincidió con SOS1 cuando este ofreció respuesta. Además hubo dos problemas cuya evaluación inicial coincidió con la del óptimo, siendo 0 en ambos casos. ProductMode obtuvo punto infactibles en 3 ocaciones. 




\subsubsection{C-Estacionario}

En los problemas de C-Estacionario hubo 2 problemas para los cuales no hubo óptimo. En los 3 restantes la evaluación de los óptimos ofrecidos por los métodos y los puntos estacionarios iniciales fueron cercanas, en estos casos SOS1 logró dar solución en todos al igual que ProductMode, aunque este devolvió óptimos locales y   Big-M no logró ofrecer solución en uno de estos casos.


 

\subsubsection{M-Estacionario}

Para los problemas con este tipo de punto estacionario solo hubieron 2 casos en los que se halló óptimo, en ambos los valores de la evaluación de punto inicial y del óptimo fueron casi iguales, en el primero solo Big-M dió solución; mientras que en el segundo los 3 métodos devolvieron resultados, siendo el de ProductMode un óptimo local.  
  
\subsubsection{Fuertemente Estacionario}

Análogo al tipo de punto anterior  fueron 2 problemas los que tuvieron óptimos con características análogas a las anteriores y coincidieron los tipos de resultados de ProductMode, en este caso en ambos problemas los 3 métodos obtuvieron solución en ambos casos. 
   



\subsection{Problemas Cuadráticos}


%region Resultados Cuadráticos
\subsubsection{$\alpha =0$}
En el caso en que los puntos estacionarios tengan multiplicador $\alpha=0$, existio al menos un metodo que fue capaz de hallar la soluci\'on óptima. El método Big-M solo funciono en un caso y calculó una solucion con peor evaluacion de la función objetivo respecto al punto estacionario inicial. Mientras ProductMode y SOS1 hallaron soluciones en todos los casos, sin embargo solo en un caso logro mejorar el punto inicial y propone una solucion peor en otros dos casos. 

\subsubsection{C-Estacionario}   
Como en  el caso anterior al menos un algoritmo fue capaz de resolver los modelos. 
El método Big-M solo funcionó en un problema donde mejoro con respecto a la evaluacion del punto estacionario inicial, al igual que  ProductMode y SOS1. Además en 2 problemas los metodos hallaron puntos con peor evaluación de la función objetivo que en el punto estacionario inicial. En otros 2 modelos se obtuvieron óptimos cercanos a este.



    
\subsubsection{M-Estacionario}
  
Para este tipo de puntos en todos los problemas el criterio de parada fue porque se habia alcanzado la optimalidad en al menos un algoritmo.
Big-M solo funcionó en un problema donde hallo una solucion cercana al del punto estacionario inicial siendo el más rapido en este problema. Solo en 3 problemas  se logró  un óptimo con evaluación  similar al punto estacionario inicial  y   cercano a este. ProductMode solo obtuvo óptimos locales. SOS1 obtuvo soluciones de forma más rapida en dos problemas mientras que ProductMode en el resto. En dos casos la solucion obtenida es peor que el punto propuesto.
    
\subsubsection{Fuertemente Estacionario} 
Hubo un problema que ningun enfoque logro resolver. En cuanto al resto  Big-M solo dio solución en un problema, construido usando el ex9.2.3 como base. Los métodos ProductMode y SOS1 solo lograron hallar tres puntos factibles que eran puntos óptimos locales y en dos casos logró mejorar la solucion inicial, pero con tiempos similares. Hubo un problema que ningún método logró resolver.


%endregion
\subsection{Problemas No Convexos}

En este caso solo se resuelve  la reformulacion KKT con el paquete IPOPt, ya que BilevelJump solo resuelve problemas convexos. Los resultados son muy similares. En ningun caso logro mejorar el punto inicial hallado. Para $\alpha =0$ esto sucedio en todos los casos excepto en el problema MitsosBarton2006Ex323 en que el algoritmo fallo. Para  problemas con puntos C-estacionarios conocidos generados,  en un caso coincidieron y en  los problemas MitsosBarton2006Ex313 y MitsosBarton2006Ex314 las soluciones halladas por Julia fueron peores que la ya conocida. Vale destacar que el valor de las variables del nivel superior son iguales al punto estacionario inicial. En el resto la soluciones el algoritmo no hallo solucion factible.   Para puntos M-estacionarios, solo se obtuvieron solucines los problemas MitsosBarton2006Ex313 y MitsosBarton2006Ex314, obteniendo en ambos casos peores resultados del valor óptimo hallado por Julia en comparación con el valor del punto estacionario inicial. En la clase de fuertemente conexos, excepto en el problema MitsosBarton2006Ex323,
 se obtuvieron puntos óptimos. Solo mejoran levemente su valor en MitsosBarton2006Ex312. 
 Además, en todos los casos, los valores de las variables del nivel superior coinciden.
     

    




  


\subsection{Análisis de los resultados}


El análisis de los experimentos realizados en este capítulo permite observar distintos comportamientos según el tipo de problema analizado.
%Lineales 
En los problemas lineales, se evidenció que, a medida que se imponen condiciones más fuertes en los puntos, es más común que los métodos encuentren óptimos en la vecindad del punto original. 
Sin embargo, estas mismas condiciones también incrementan la posibilidad de que los algoritmos no logren encontrar una solución óptima y terminen en puntos infactibles. 
En particular, el método ProductMode fue el que  tuvo como salida un punto infactible más veces ,seguido del método SOS1, además de los factibles todos fueron óptimos locales y un comportamiento a destacar es que en caso que coincidiera con que SOS1 en devolver óptimos factibles era común que la evaluación de los estos fuera cercana.
Además Big-M tuvo mayormente problemas asociados al valor de las cotas $M_p$ y $M_d$. 
Cabe destacar que en ningún caso el valor objetivo fue peor que el valor inicial estacionario. 

% Cuadráticos
En los problemas cuadráticos, excepto en el caso fuertemente estacionario no se encontraron dificultades en los algoritmos para encontrar un punto óptimo. En ellos existe una mejora entre los tipos de puntos con condiciones más fuertes respecto a que el óptimo hallado por Julia se encuentre en una vecindad del punto estacionario inicial. 
Continuó la tendencia de ProductMode y SOS1 que si ambos encontrarán un óptimo la evaluación de este similar en ambos. 
Y en estos Big-M solo pudo hallar puntos estacionarios en el problema ex9.2.3.
% No convexos
En el caso de los problemas no convexos, los resultados sugieren que, cuanto más fuertes son las condiciones del punto, los algoritmos no encuentran puntos óptimos mejores que el estacionario inicial. Esto parece deberse a que, por la propia reformulación del problema, es más probable que no se pueda optimizar correctamente el problema del nivel inferior. Además, la tendencia indica que, mientras más fuertes sean las condiciones del punto, es más probable que las variables del nivel superior coincidan en el punto óptimo hallado por Julia y el punto estacionario inicial.

En conclusión, los resultados de los experimentos muestran que la fortaleza de las condiciones impuestas 
sobre los puntos tiene un impacto significativo en el desempeño de los algoritmos de optimización. 
Cada tipo de problema presenta comportamientos diferenciados, lo que sugiere la necesidad de considerar 
cuidadosamente estas condiciones al aplicar métodos de optimización en distintos contextos.
