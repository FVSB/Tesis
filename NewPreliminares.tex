\chapter{Preliminares}


La optimización binivel es un problema de optimización donde un subconjunto de variables debe ser la solución óptima de otro problema de optimización, parametrizado por las variables restantes. Este problema tiene dos niveles jerárquicos de decisión: el nivel superior (líder) y el nivel inferior (seguidor).
Este tiene dos características principales: primero, el problema del nivel inferior actúa como una restricción para el nivel superior; segundo, la solución del nivel inferior depende de las variables del nivel superior, creando una interdependencia entre ambos niveles. Por ello, el líder debe anticipar la respuesta óptima del seguidor al tomar decisiones.
%Explicación breve de binivel
En términos abstractos, la optimización binivel busca minimizar una función objetivo de nivel superior, $F(x, y)$, donde $x$ son las variables de decisión del líder y $y$ son las variables del seguidor. 

% Explicación del capitulo
En este capítulo se abordará los conocimientos necesarios para el desarrollo de esta tesis. La primera seccio\'on trata  sobre Optimización Binivel: la definici\'on de solucion basada en la existencia de una cierta cooperacion entre lideres y seguidores (caso  optimista) y la reformulación KKT. Luego se presentan los conceptos fundamentales  de soluci\'on, regularidad y estacionariedad para   Problemas Matemáticos con Restricciones de Equilibrio (MPEC). La tercera secci\'on contiene las prinicipales transformaciones que se aplican a las restricciones de complementariedad para la solucion num\'erica del modelo. Por último, se presenta la modelación de los problemas binivel en el lenguaje de programación Julia y los métodos seleccionados implementados en este lenguaje para su resolución. 

\section{Optimización Binivel }
%Intro de la sección
El problema de optimización binivel en general se define de la siguiente manera
\begin{equation} \label{eq:Def1Binivel}
    \begin{array}{l}
       \min_{x} \quad F(x, y)\\
        s.a \left\{ \begin{array}{l}
            x \in \cal{T} \\
             y \in S(x) = \arg  \min_{y} \{ f(x, y) \quad s.a \quad y \in  \cal{H}\}\\
            (x,y) \in {\cal{M}}^0 
        \end{array}\right.
        \end{array} \end{equation}
En la mayor\'ia de las aplicaciones, los problemas de optimizacion del nivel inferior y superior son modelos de programaci\'on matem\'atica, por lo  que, sin p\'erdida de generalidad, se asume que  ${\cal{T}}=\mathbb{R}^n$,  $\cal{H}$ es  $\{y\in \mathbb{R}^m\in v_j(x, y)\leq 0,\;j=1,\ldots,q\}$  y
  ${\cal{M}}^0=\{(x,y)\in\mathbb{R}^{n+m},\;g_i(x, y)\leq 0,\;i=1,\ldots,q\}$. El problema es  
\begin{equation}
\begin{aligned}
& \min_{x} \; F(x, y) \\
& \text{sujeto a } \\
& g_i(x, y)\leq 0,\;i=1,\ldots,q, \\
& y \in \argmin_{y} \left\{ f(x, y) \mid v_j(x, y)\leq 0,\;j=1,\ldots,q \right\}
\end{aligned}
\label{eq:ProblemaGeneral}
\end{equation}
donde 
$    x \in R^{n},\; y \in R^{m}$, $ F(x,y) : \mathbb{R}^{n} \times \mathbb{R}^{m} \to \mathbb{R},$ $ g_i(x,y)  : \mathbb{R}^{n} \times \mathbb{R}^{m} \to \mathbb{R} ,$, $i=1,\ldots, q$,  $f(x,y) : \mathbb{R}^{n} \times \mathbb{R}^{m} \to \mathbb{R},$  $v_j(x,y)  : \mathbb{R}^{n} \times \mathbb{R}^{m} \to \mathbb{R} ,$ $j=1,\ldots, s$.
En el enfoque optimista, se asume que el seguidor, que actúa en el nivel inferior, elegirá la solución más favorable para el líder, quien toma decisiones en el nivel superior. Este es considerado más tratable y, en ciertas situaciones favorables, puede simplificarse a un problema convexo. Además, en el contexto de múltiples objetivos, el enfoque optimista permite alcanzar el mejor frente de Pareto posible, ver \cite{DempeyZemkoho2020}.

%\begin{center}   
%    Bajo el enfoque optimista :
%    \end{center}
    % Enfoque optimista (selección favorable)
    \begin{equation}  \label{eq:EnfoqueOptimistaGeneral}
    \begin{matrix}
    & \min_{x} \; \inf_{y \in S(x)} F(x, y) \\& g_i(x, y)\leq 0,\;i=1,\ldots,q, \\
    & \text{con } S(x) = \argmin_{y} \left\{ f(x, y) \mid v(x, y) \leq 0 \right\}
    \end{matrix}
    \end{equation}
    \captionof{figure}{Problema de optimización bajo el enfoque optimista.}

% Enfoque pesimista
Por otro lado, el enfoque pesimista asume que el seguidor seleccionará la opción menos favorable para el líder entre las soluciones óptimas disponibles, el cual es más complejo de resolver y puede incluso no tener solución. A menudo, se requieren reformulaciones para abordar estos problemas, lo que lo convierte en un reto teórico y computacional significativo en situaciones de múltiples objetivos, conduce al peor frente de Pareto posible, ver \cite{Sinha2017ARO}.
%\begin{center}
%    Bajo el enfoque pesimista:
%\end{center}
% Enfoque pesimista (peor caso)
\begin{equation}
\begin{aligned}
& \min_{x} \; \sup_{y \in S(x)} F(x, y) \\& g_i(x, y)\leq 0,\;i=1,\ldots,q, \\
& \text{con } S(x) = \argmin_{y} \left\{ f(x, y) \mid v(x, y) \leq 0 \right\}
\end{aligned}
\label{eq:EnfoquePesimistaGeneral}
\end{equation}
\captionof{figure}{Problema de optimización bajo el enfoque pesimista.}
%Decir que el optimista es mejor
Es relevante destacar que la mayoría de la literatura se centra en el enfoque optimista debido a su mayor facilidad de tratamiento. Sin embargo, el otro también tiene su utilidad, especialmente en la modelación de situaciones donde se considera la aversión al riesgo, ver \cite{DempeyZemkoho2020}. En este contexto, los términos ''líder'' y ''seguidor'' se utilizan para describir los roles en el modelo a optimizar; el líder toma decisiones considerando las posibles reacciones del seguidor, quien a su vez reacciona seleccionando su mejor opción, ver \cite{Sinha2017ARO}.

% Decir que se va ha hablar del enfoque optimista
Dado que en la tesis trataremos sobre problemas binivel de enfoque optimista mostraremos algunos resultados referidos al modelo resultante.

Primeramente es importante notar el siguiente resultado, ver \cite{Scmidtbiblio}.

\begin{proposition} El problema de optimización binivel optimista \eqref{opt} se formula equivalentemente como:
\begin{equation}\label{eq:DefBinivelOptimista} 
\begin{matrix}
    \min_{x , y} & \quad F(x, y) \notag \\
    \text{s.t.} & \quad g_i(x, y) \leq 0, i=1\ldots q,  \notag \\
    & \quad y \in S(x), \end{matrix}\end{equation}
  
donde $S(x)$ es el conjunto de soluciones óptimas del problema parametrizado por $x$ 
 \begin{equation}
\begin{matrix}   \min_{y \in Y(x)} & \quad f(x, y)  
    \text{s.t.} & \quad v_j(x, y) \leq 0, j=1\ldots s, \notag \end{matrix}\end{equation}


\end{proposition}
De ah\'i  que a partir de ahora se considerar\'a el problema \eqref{eq:DefBinivelOptimista} y se le llamar\'a indistintamente problema de dos niveles. 
 % Hablar sobre el enfoque optimista
%En el caso del enfoque optimista si para el nivel inferior existen más de un punto que resuelve el problema del nivel inferior y tomará la que más beneficie al nivel superior. 
 % Decir que solo restricciones desigualdad
Los  problemas de dos niveles pueden ser reformulados en un problema de un solo nivel al reemplazar el problema del nivel inferior por las condiciones KKT de este en las restricciones del primer nivel. 
		
		%Para el caso de los SLSMG donde se tiene un problema de optimización en el nivel inferior este sustituye por de las condiciones KKT de este, obteniendo un MPEC \autocite{aussel2020}.
        
% 
        \begin{equation}\label{eq:KKT_Optimista}   
            \begin{array}{l}
                \underset{\substack{x, y, \lambda_j}}{\min} \quad F(x, y)\\
                s.a \left\{ 
                \begin{array}{l}
                    g_i(x, y) \leq 0, i=1\ldots q,\\
                    \nabla_{y} f(x, y) + \sum_{j=1}^{s} \nabla_{y} v_j(x, y) \lambda_j = 0, \\
                    v_j(x, y) \leq 0, j=1\ldots s,\\
                    v_j(x, y)\lambda_j = 0, j=1\ldots s, \\
                    \lambda_j \geq 0, j=1\ldots s.\\
                \end{array}\right.
            \end{array}
        \end{equation}
     

% Añadir aclaratoria
Los tres últimos grupos de restricciones expresan que $v$ y $\lambda$ están restringidas en signo y que al menos una es 0. Estas condiciones son conocidas como \textbf{restricciones de complementariedad}. Estos modelos corresponden a la clase de problemas de programación matemática con restricciones de complementariedad (MPEC). A continuación, presentamos los resultados de esta área necesarios para el desarrollo de esta tesis.
%TODO: Como se dijo en la intro existe otra forma, en un problema de programacion matematica  usando funcion del valor extremal sin embargo salvo en casos muy particulares esta no tiene una expresion explicita. La ventaja dsel kkt por mpec es que es una forma explicita, pero se requiere algun tipo de condicion de regularidad del conjunto como LICQ independencia  de v activa, que caso ded no cumpliser poder existir puntos optimos que no lo recoga el kkt. 

\section{Programaci\' on Matemáticos con Restricciones de Equilibrio (MPEC)}
%Aca va la sección que explica los MPEC
% Que es un MPEC
Un \textbf{problema de Programaci\'on Matemático con Restricciones de Equilibrio (MPEC)} es un tipo de  problema de optimizaci\'on no lineal que incluye restricciones de equilibrio, específicamente, restricciones de complementariedad.

%Formula MPEC Genérico
\begin{equation}
\begin{aligned}
\min  &\quad  f(z)  \\
\text{s.t.} &\quad \begin{matrix} g_i(z)& \leq& 0, &i=1,\ldots,q, \\ h_k(z) &=& 0,&k=1\ldots,m, \\
 G_j(z) &\geq& 0, & j=1,\ldots,s,& H_j(z) &\geq& 0, & j=1,\ldots,s, \end{matrix}
\\&G_j(z)^T H_j(z) = 0,\; j=1,\ldots,s. \\
&\text{Definición de MPEC} \\
\end{aligned}  
%\tag{\theequation} 
\label{eq:DefMpec}
\end{equation}

%Dimensiones MPEC Genérico
donde $f: \mathbb{R}^{\hat{n}} \to \mathbb{R}$, $g: \mathbb{R}^{\hat{n}} \to \mathbb{R}$, $h: \mathbb{R}^{\hat{n}} \to \mathbb{R}$, $G: \mathbb{R}^{\hat{n}} \to \mathbb{R}$, y $H: \mathbb{R}^{\hat{n}} \to \mathbb{R}$ son funciones continuamente diferenciables. 
El término de complementariedad se debe a la existencia de las restricciones hom\'onimas 
%Ecuación para poner que son las restricciones de complementariedad
\begin{equation}
    G_j(z) \geq 0, \; H_j(z) \geq 0, \quad G_j(z)^T H_j(z) = 0,\quad  j=1,\ldots,s. \\ \label{eq:RestriccionesComplementariedadAbstracto}
\end{equation}

Debido a las restricciones de complementariedad, los MPEC no cumplen con las condiciones de regularidad estándar, lo que hace que las condiciones de KKT no sean directamente aplicables como condiciones de optimalidad de primer orden. Los MPEC son utilizados para modelar problemas donde existen restricciones de equilibrio, como problemas de ingeniería y economía, ver \cite{Flegel2003AFJ,DempeyZemkoho2020}.


%\subsection{Resultados sobre MPECs}

%Notación de los indices activos del documento
A continuación como en \cite{Flegel2003AFJ}, se introduce las siguientes definiciones, \'utiles para la obtenci\'on de condiciones necesarias de optimalidad.
\begin{definition}[Conjunto de Índices]
Dado un vector factible $z^*$ del MPEC \eqref{eq:DefMpec}, definimos los siguientes \textit{conjuntos de índices}:
\begin{equation}
\begin{aligned}
J_G&:=& J_G(z^*) := \{i|G_i(z^*) = 0, H_i(z^*) > 0\} \\
J_{GH}&:=& J_{GH}(z^*) := \{i|G_i(z^*) = 0, H_i(z^*) = 0\}  \\
J_H &:= &J_H(z^*) := \{i|G_i(z^*) > 0, H_i(z^*) = 0\}  \\
\end{aligned}
\label{eq:ConjuntoDeIndices} 
\end{equation}
\end{definition}

% Definición de TNLP Problema No Lineal Ajustado
Para definir condiciones de regularidad para MPEC, introducimos el siguiente problema, dependiente de $z^*$:

\begin{definition}[Programa No Lineal Relacionado (RNLP)]

Un \textit{Programa No Lineal Relacionado $RNLP_{a,b} := RNLP_{a,b}(z^*)$} es:
%TODO: INcomporar indices y rango en que se mueven
\begin{equation}
\begin{aligned}
\min  &\quad  f(z)  \\
\text{s.t.} &\quad \begin{matrix} g_i(z)& \leq& 0, &i=1,\ldots,q, \\ h_k(z) &=& 0,&k=1\ldots,m, \\
 G_j(z) &=& 0, & j\in J_G\cup J_{a},& G_j(z) &\geq& 0, & j\in J_H,\\ 
H_j(z) &=& 0, & j\in J_H\cup J_{b},& H_j(z) &\geq& 0, & j\in J_G,\end{matrix}\\
& \text{Problema No Lineal Ajustado (TNLP)}  
\end{aligned}
\label{eq:ProblemaAbstractoTNLP}
\end{equation}
    donde $a\cup b=J_{GH}$.
\end{definition}

El TNLP \eqref{eq:ProblemaAbstractoTNLP} puede  usarse para definir variantes de regularidad y condiciones necesarias de optimalidad  adecuadas para MPEC como son la  restricción estándar de independencia lineal (LICQ en su forma abreviada) y la de punto de KKT .

\begin{definition}[MPEC-LICQ]
El MPEC \eqref{eq:DefMpec} se dice que satisface la \textit{MPEC-LICQ}  en un vector factible $z^*$ si los correspondientes $RNLP_{a,b}(z^*)$ satisfacen la LICQ  en ese vector $z^*$.
\end{definition}
    Cabe destacar que si la LICQ se cumple en  $RNLP_{a,b}(z^*)$ para una partici\'on $(a,b)$ se cumple para todas. 
% Hacer notar que un mínimo de z^* implica la existencia de \lambda^* ....
%En este punto, es importante notar que bajo MPEC-MFCQ, un mínimo local $z^*$ del MPEC \eqref{eq:DefMpec} implica la existencia de un multiplicador de Lagrange $\lambda^*$ tal que $(z^*, \lambda^*)$ satisface las condiciones KKT para el programa \eqref{eq:ProblemaAbstractoTNLP}. Por lo tanto, si asumimos que MPEC-MFCQ se cumple para un mínimo local $z^*$ del MPEC \eqref{eq:DefMpec}, podemos usar cualquier multiplicador de Lagrange $\lambda^*$ (que ahora se sabe que existe) para definir el MPEC-SMFCQ, es decir, tomando $(z^*, \lambda^*)$.

%Definición de los puntos estacionarios del MPEC
% Flegel and Kanzow 2003
En el contexto de los MPEC en \cite{Flegel2003AFJ} se exponen varios tipos de puntos estacionarios que son cruciales para analizar la optimalidad, los cuales son los siguientes:
\begin{definition}[Punto Factible]
    Un \textit{punto factible} $z^*$ del MPEC se llama débilmente estacionario si existe un multiplicador de Lagrange $ (\mu, \alpha, \beta, \gamma)$ tal que se cumplen las siguientes condiciones:
    
%TODO: USar multiplicadores analogos a como esta en el bijnivel de miu lambda beta 
% EN este orde  mui-g, alpha-h beta-G gamma-H
\begin{align}
& \nabla f(z^*) + \sum_{i=1}^q \mu_i\nabla g_i(z^*) + \sum_{k=1}^{q_0} \alpha_k\nabla h_k(z^*) - \sum_{i=1}^{s} [\beta_j\nabla G_j(z^*) + \gamma_j\nabla H_j(z^*)] = \vec{0} \notag\\
    & \quad \begin{aligned}
        & \beta_j,\; j\in {J_G} \text{ libre}, \quad  \beta_j,\; j\in _{J_G\cup J_{GH}} \text{ libre}, \quad \beta_j,\; j\in _{J_H}= 0, \\
        &  \gamma_j,\; j\in _{J_H} \text{ libre}, \quad  \gamma_j,\; j\in _{J_G\cup J_{GH}} \text{ libre}, \quad \gamma_j,\; j\in _{J_G}= 0,  \\
        & g_i(z^*) \leq 0, \quad \mu_i \geq 0, \quad \mu_i g_i(z^*) = 0, i=1,\ldots, q.
    \end{aligned} \\
& \label{eq:Definici\'on_punto_debilemente_estacionario} \notag
\end{align}
\end{definition}

% Definición de puntos estacionarios
Este concepto de estacionariedad es equivalente al cumplimiento de la estacionariedad cl\'asica en el problema $RNLP_{J_{GH},J_{GH}}$. De ah\'i que  es una condición relativamente débil. Existen conceptos más fuertes de estacionariedad que se derivan y estudian en otros lugares. En particular, se tienen las siguientes definiciones:
% un punto factible $z$ con el correspondiente multiplicador de Lagrange $\lambda = (\lambda^g, \lambda^h, \lambda^G, \lambda^H)$ se llama:


% C-estacionario
 \begin{definition}[Punto C-estacionario]
  El punto $z^*$ es: \textit{C-estacionario} si, para cada $i \in J_{GH}$, $\lambda_i^G\lambda_i^H \geq 0$ se cumple.
\end{definition}
%M-Estacionario
\begin{definition}[Punto M-estacionario]
    El punto $z^*$ es: \textit{M-estacionario} si, para cada $i \in J_{GH}$, o bien $\lambda_i^G,\lambda_i^H > 0$ $\vee$ $\lambda_i^G \lambda_i^H = 0$.
\end{definition}
%Fuertemente estacionario
 \begin{definition}[Punto Fuertemente estacionario]
    El punto $z^*$ es: \textit{fuertemente estacionario}  si, para cada $i \in J_{GH}$, $\lambda_i^G, \lambda_i^H \geq 0$.
\end{definition}

%TODO:
La $C$ y la $M$ estacionariedad  son condiciones necesarias de optimalidad bajo ciertas condiciones de regularidad, m\'as d\'ebiles que la  MPEC-LICQ. La fuerte conlleva al siguiente resultado:
% Teorema que si z^* es min local del MPEC Si se cumple la LICQ entonces existe .....
\begin{theorem} 
Sea $z^* \in \mathbb{R}^n$ un mínimo local del MPEC \eqref{eq:DefMpec}. Si MPEC-LICQ se cumple en $z^*$, entonces existe un único multiplicador de Lagrange  tal que $(z^*, \mu, ^*)$ es \textit{fuertemente estacionario}.
\end{theorem}
O sea el punto $z^*$ es un punto estacionario del problema relajado 

\begin{equation}
\begin{array}{cl}
\min  &\quad  f(z)  \\
\text{s.t.} &\quad  g_i(z) \leq 0, \;i=1,\ldots,q, \\ &h_k(z) = 0,\;k=1\ldots,m, \\
&\begin{array}{ccccccccccccccccc}G_j(z) &=& 0, & j\in J_G& G_j(z) &\geq& 0, &j\in J_{GH},& G_j(z) &\geq& 0, & j\in J_H,\\ 
H_j(z) &=& 0, & j\in J_H& H_j(z) &\geq& 0, & j\in J_{GH},& H_j(z) &\geq& 0, & j\in J_G,\end{array}\\
& \text{Problema No Lineal Relajado }  
\end{array}
\label{eRNLP}
\end{equation}Los algoritmos buscan al menos converger a puntos de este tipo.  En la pr\'oxima secci\'on se revisar\'an las reformulaciones que se resuelven  las bibliotecas de Julia.
\section{Métodos de Reformulación para Optimización Binivel}
La optimización binivel presenta desafíos particulares debido a su naturaleza jerárquica y las condiciones de complementariedad resultantes. A continuación, se presentan los principales métodos de reformulación implementados en la literatura, basados en la transformación del MPEC \eqref{eq:KKT_Optimista}.
\subsection{Método Big-M}

El método Big-M (Fortuny-Amat y McCarl)  es una técnica fundamental para reformular problemas de optimización binivel en problemas MPEC. 
Este método aborda específicamente las condiciones de complementariedad que surgen en estas reformulaciones, transformando el problema original en un problema de programación lineal mixta entera (MILP).

La reformulación mediante Big-M introduce un parámetro M suficientemente grande y variables binarias para transformar las condiciones de complementariedad no lineales en restricciones lineales. Para cada condición de complementariedad 
$v_j(x,y)\lambda_j = 0$ en \eqref{eq:KKT_Optimista}, el método introduce una variable binaria  $\delta_j \in \{0,1\}$ y cotas superiores $M_p$, $M_d$ bajo  las siguientes restricciones:

\begin{align}
    v_j(x,y) &\geq -M_p(1 - \delta_j) \notag \\
    \lambda_j &\leq M_d \delta_j \\
	%TODO: EN vez sde f_j poner \delta_j
    \delta_j &\in \{0,1\} \notag
\end{align}

donde $M_p$ y $M_d$ son valores grandes para las variables primales y duales, respectivamente. La efectividad del método depende crucialmente de la selección apropiada de estos valores, que deben ser suficientemente grandes para no excluir la solución óptima, pero no excesivamente grandes para evitar inestabilidades numéricas \cite{BilevelJump}.


\subsection{Método SOS1}

El método de Conjuntos Ordenados Especiales tipo 1 (SOS1) evita el uso de parámetros Big-M mediante restricciones de tipo conjunto. Para cada par complementario $(v_j, \lambda_j)$, $j=1,\ldots, s$:

\begin{equation}\label{eq:SOS1_reform}\begin{matrix}v_j(x,y)=s_j\\
%DONDe SOS1 es v_j * \lambda_j 
[s_j; \lambda_j] \in \text{SOS1} \end{matrix}
\end{equation}
 donde $SOS1=\{(a,b)\in \mathbb{R}: a,b\geq 0,\; ab=0\}$


Esta restricción fuerza que al menos una variable en el par sea cero, preservando la no linealidad original sin necesidad de cotas. Note que SOS1 es un cono. Esta es una reformulaci\'on del  MPEC como un problema de optimizaci\'on c\'onica. Es particularmente eficaz en MPECs con restricciones del tipo $u\in K$, donde $K$ es un cono, pues sigue siendo un problema de optimizaci\'on c\'onica  y se pueden aplicar algoritmos espec\'ificos para la resolucion de este tipo de modelos, \cite{BilevelJump}. La dificultad principal es que el cono es no convexo. Una aplicaci\'on de este enfoque se encuentra en \cite{SadddiquiNaturalGasSOS1}.


\subsection{Método ProductMode}

El método ProductMode representa un enfoque directo para manejar las condiciones de complementariedad en su forma de producto original. Este método es particularmente útil cuando se trabaja con solucionadores de programación no lineal (NLP), aunque no garantiza la optimalidad global.

La implementación del ProductMode mantiene la restricción de complementariedad en su forma original:

\begin{equation}
    v_j(x,y) \cdot \lambda_j \leq t \label{eq:ProductMode_reg}
\end{equation}

donde $t > 0$ es un parámetro de regularización pequeño. Esta formulación, aunque no satisface las condiciones de calificación de restricciones estándar, es útil para obtener soluciones iniciales y puede ser especialmente efectiva cuando se combina con solucionadores NLP, ver \cite{BilevelJump}. sin embargo, bajo condiciones naturales, la sucesi\'on que genera converge a puntos C  estacionarios y bajo regularidad hasta fuertemente estacionarios, ver \cite{scholtes12}.  

% TODO: hjacer suempre cierre capitulo, y dicinedo que se dijo y motivar


La Tabla \ref{tab:comparacion_metodos} resume los requisitos y características de cada método:

\begin{table}[H]
\centering
\begin{tabular}{l|l|l}
\textbf{Método} & \textbf{Solver Requerido} & \textbf{Ventajas} \\ \hline
Big-M & MIP & Estabilidad numérica controlada \\
SOS1 & MIP con SOS1 & Sin parámetros ad-hoc \\
ProductMode & NLP & Manejo de no linealidades \\
\end{tabular}
\caption{Comparación de métodos de reformulación}
\label{tab:comparacion_metodos}
\end{table}

Para casos con restricciones no lineales $v_j(x,y)$, se recomienda combinar ProductMode con técnicas de linealización por tramos \cite[Apéndice B]{BilevelJump}. Todos estos métodos están implementados en BilevelJuMP.jl, permitiendo experimentación con reformulaciones que se pueden encontrqr en \cite[Sección 4]{BilevelJump}.

%\section{Add}
%\begin{equation}
%    \min_{x,y,\lambda_j,f_j} F(x,y)
%\end{equation}
%
%sujeto a:
%\begin{align}
%    & g_i(x,y) \leq 0, && i = 1,\ldots,q, \\
%    & \nabla_y f(x,y) + \sum_{j=1}^s \nabla_y v_j(x,y) \lambda_j = 0, \\
%    & v_j(x,y) \leq 0, && j = 1,\ldots,s, \\
%    & \lambda_j \geq 0, && j = 1,\ldots,s, \\
%    & v_j(x,y) \geq -M_p \cdot (1-f_j), && \text{(no lineal si } v_j \text{ es no lineal)} \\
%    & \lambda_j \leq M_d \cdot f_j, && j = 1,\ldots,s, \\
%    & f_j \in \{0,1\}, && j = 1,\ldots,s.
%\end{align}
% Modelación en Julia
% Se explica de que va BilevelJump
\section{Modelación en Julia}

% Que es Julia


% Que problemas resuelve
Este paquete permite abordar una amplia variedad de tipos de problemas. En este trabajo usaremos las  bibliotecas $JuMP$ y BilevelJuMP.
% Añadir explicación MPEC
\subsection*{JuMP}
Esta biblioteca permite resolver problemas de programaci\'on matem\'atica no lineal y discreta. O sea
$$
    \min F(z)$$
sujeto a:
\begin{align}
    & g_i(z) \leq 0, && i = 1,\ldots,q, \\
    & h_k(z)  = 0, && i = 1,\ldots,q_0,\\
\end{align} donde $z\in \mathbb{R}^p\times  \mathbb{R}^{\hat{n}-p}$.
JuMP  permite gestionar una variedad de casos diferenciando como si las variables son continuas o discretas y  las restricciones  cuadráticas, lineales, de cotas o no lineales y, similarmente, si   la funci\ 'on objetivo es cuadrática, lineal o no lineal. También permite definir  restricciones de complementariedad  y ofrece métodos para resolver MPECs como ******.
  %TOD: Poner esto despues de expluicar las reformulaciones
Pqra m\'as detalles sobre lq biblioteca, ver \cite{JuMPPaper}.
\subsection*{BilevelJuMP}BilevelJuMP.jl es un paquete de Julia diseñado para modelar y resolver problemas de \textbf{optimización binivel}, también conocidos como problemas de optimización de dos niveles o jerárquica, para más detalles ver \cite{BilevelJump}.

BilevelJuMP.jl facilita la modelación ya que el problema del seguidor se representa usando la   sintaxis de JuMP que, como se mencionó en la parte anterior,  permite incluir de forma diferenciada  las restricciones lineales y no lineales, las variables continuas y enteras, y diferentes tipos de  funciones objetivos.
Para el problema del nivel superior gestiona sus restricciones y la funcion objetivo de forma análoga. 

%TODO: MOdificar esto para decir que hace esto.
     Los usuarios pueden experimentar con diversas reformulaciones para las restricciones de complementariedad en los problemas MPEC, incluyendo SOS1 y McCarl (Big-M), entre otros.
    %TODO: POner que es comun a los dos 
 BilevelJuMP.jl puede utilizar tanto solucionadores de \textbf{programación lineal mixta entera (MIP)} como solucionadores de \textbf{programación no lineal (NLP)}, dependiendo de las características del problema y la reformulación elegida. 

%\subsection{Limitaciones del BilevelJuMP.jl}

A pesar de sus capacidades, BilevelJuMP.jl presenta algunas limitaciones, entre las cuales se encuentran:

\begin{itemize}
    \item Enfrentar dificultades en problemas altamente no lineales o con estructuras de optimización complejas que no se puedan representar adecuadamente en la sintaxis de JuMP.
    \item Existencia de ciertas restricciones que podrían no ser compatibles o que requieren transformaciones adicionales que podrían complicar el modelo.
    \item El problema es de gran escala afectando el rendimiento del solver, el cual puede ser un factor crítico.
    \item La formulación y resolución de problemas muy específicos o especializados podrían no estar completamente optimizadas en el paquete.
\end{itemize}

Teneindo en cuenta la posibilidad de que los m\'etodos de soluci\'on converjan a puntos estacionarios de distinto tipo, resulta interesante comprobar si, conocido un punto de esta naturaleza, el algoritmo logra obtener un punto con  mejor evaluaci\'on de la funcion objetivo. Esta es la motivaci\'on para el dasarrollo del generador de problemas prueba, objeto de esta tesis y que se presentar\ ' en el pr\ oximo cap\'itulo.
% Explicación algoritmos 
begin{equation}
%    \min_{x,y,\lambda_j,f_j} F(x,y)
%\end{equation}
%
%sujeto a:
%\begin{align}
%    & g_i(x,y) \leq 0, && i = 1,\ldots,q, \\
%    & \nabla_y f(x,y) + \sum_{j=1}^s \nabla_y v_j(x,y) \lambda_j = 0, \\
%    & v_j(x,y) \leq 0, && j = 1,\ldots,s, \\
%    & \lambda_j \geq 0, && j = 1,\ldots,s, \\
%    & v_j(x,y) \geq -M_p \cdot (1-f_j), && \text{(no lineal si } v_j \text{ es no lineal)} \\
%    & \lambda_j \leq M_d \cdot f_j, && j = 1,\ldots,s, \\
%    & f_j \in \{0,1\}, && j = 1,\ldots,s.
%\end{align}